[{"path":[]},{"path":"https://ui-research.github.io/climateapi/CLAUDE.html","id":"performance-critical-functions","dir":"","previous_headings":"","what":"Performance-Critical Functions","title":"climateapi Package Development Notes","text":"following functions rely large input datasets slow. Speed optimizations using duckplyr, parquet, arrow, tidytable critical functions: get_ihp_registrations() - IHP registration data can large (millions records) get_nfip_policies() - NFIP policy data exceeds 80 million records nationally get_nfip_claims() - NFIP claims data exceeds 2 million records","code":""},{"path":"https://ui-research.github.io/climateapi/CLAUDE.html","id":"testing-strategy-for-large-data-functions","dir":"","previous_headings":"Performance-Critical Functions","what":"Testing Strategy for Large-Data Functions","title":"climateapi Package Development Notes","text":"Tests functions load data top test file reuse object success tests. avoids repeated /O test runs. Validation tests (expected fail) call function directly without using cached data object.","code":""},{"path":"https://ui-research.github.io/climateapi/CLAUDE.html","id":"performance-considerations","dir":"","previous_headings":"Performance-Critical Functions","what":"Performance Considerations","title":"climateapi Package Development Notes","text":"modifying functions: - Prefer arrow::read_parquet() CSV reads - Use tidytable dtplyr grouped operations large data - Avoid loading full datasets memory filtering possible - Consider chunked processing extremely large files","code":""},{"path":"https://ui-research.github.io/climateapi/CLAUDE.html","id":"testing-philosophy","dir":"","previous_headings":"","what":"Testing Philosophy","title":"climateapi Package Development Notes","text":"create skip functions unavailable dependencies. test requires package (like tidycensus) resource (like Box), dependency available tests run. something missing, ’s real problem fix, work around skip logic. acceptable skip pattern tests require external data sources legitimately may configured environments (e.g., Box path large data files). Even , validation signature tests still run.","code":""},{"path":"https://ui-research.github.io/climateapi/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 climateapi authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Economic Recovery Post Disaster","text":"post-event data affected area available months years, approach identifies historical comparison—counties experienced similar disasters similar pre-disaster characteristics—past—highlight various recovery trajectories. Contents: affected county’s pre-disaster economic baseline Employment, business, local government finance trajectories using event-study framework Typical PA/IHP/SBA flows federal programs (post-disaster period )","code":""},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"notes","dir":"Articles","previous_headings":"","what":"Notes","title":"Economic Recovery Post Disaster","text":"Critical approach observable pre-period, especially disaster-impacted county (post-period data). data lags, pre-period never run 2026 (current year time writing)–best, go ~2024 (ACS) cases 2023 (County Business Patterns, government finances). Accordingly, want pre-period long–say, 8 years preceding disaster, possible–multiple years observation, even disaster-affected county. comparison counties, hemmed side–want post-period observations , comparison disaster ideally occurs 2018-2020, giving us 3-5 post-period years. However, requires pre-period dating back early 2010… covered many datasets (e.g., ACS). Thus, tension identifying overlapping pre-period timelines comparison affected counties due historical data coverage.","code":""},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Economic Recovery Post Disaster","text":"","code":"library(climateapi) library(tidyverse) library(urbnthemes) library(crosswalk)  set_urbn_defaults(style = \"print\")"},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"parameters","dir":"Articles","previous_headings":"","what":"Parameters","title":"Economic Recovery Post Disaster","text":"Define affected county disaster characteristics. updated new event.","code":"# Affected county affected_county_fips <- \"12087\" affected_county_name <- \"Monroe County, FL\" affected_state <- \"FL\"  # Disaster characteristics disaster_type <- \"Hurricane\" disaster_year <- 2026  # Event-study window years_before <- 6 years_after <- 4"},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"preceding-disasters","dir":"Articles","previous_headings":"Parameters","what":"Preceding Disasters","title":"Economic Recovery Post Disaster","text":"","code":"disasters = get_fema_disaster_declarations(api = FALSE) disasters_affected = disasters %>%   filter(GEOID %in% affected_county_fips, incidents_natural_hazard > 0)"},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"section-1-the-affected-county-baseline-profile","dir":"Articles","previous_headings":"","what":"Section 1: The Affected County Baseline Profile","title":"Economic Recovery Post Disaster","text":"Establish pre-disaster economic conditions affected county.","code":""},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"sociodemographic-characteristics","dir":"Articles","previous_headings":"Section 1: The Affected County Baseline Profile","what":"Sociodemographic Characteristics","title":"Economic Recovery Post Disaster","text":"","code":"acs_df_2023 = arrow::read_parquet(file.path(get_box_path(), \"sociodemographics\", \"acs\", \"acs_county_2023.parquet\"))  acs_matching_variables = c(   \"median_household_income_universe_allraces\",   \"race_personofcolor_percent\",   \"population_density_land_sq_kilometer\",   \"total_population_universe\",   \"educational_attainment_degree_bachelors_percent\")"},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"hazard-damages-over-time","dir":"Articles","previous_headings":"Section 1: The Affected County Baseline Profile","what":"Hazard Damages over Time","title":"Economic Recovery Post Disaster","text":"","code":"sheldus_df = get_sheldus() %>%    summarize(.by = c(GEOID, year), damage_property_millions = sum(damage_property, na.rm = TRUE) / 1000000)  sheldus_df %>%    filter(GEOID %in% affected_county_fips) %>%   ggplot(aes(x = year, y = damage_property_millions)) +     geom_line() +     geom_point() +     scale_y_continuous(labels = scales::dollar_format(suffix = \"M\")) +     labs(x = \"Year\", y = \"Property damage (millions)\")"},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"industry-composition-over-time","dir":"Articles","previous_headings":"Section 1: The Affected County Baseline Profile","what":"Industry Composition over Time","title":"Economic Recovery Post Disaster","text":"Identify sectors may particularly vulnerable disaster type.","code":"cbp_df = cache_it(   cbp_df,    file_name = \"cbp_2016_2023\",    path = file.path(get_box_path(), \"employment\"), read = TRUE)  cbp_affected = cbp_df %>%   mutate(     county_fips = str_c(state, county),     industry_label = industry %>% str_replace_all(\"_\", \" \") %>% str_to_sentence()) %>%   filter(county_fips %in% affected_county_fips)  top_8_industries = cbp_affected %>%   filter(year == 2023, industry != \"total\") %>%   arrange(desc(employees)) %>%   slice(1:8) %>%   pull(industry)  cbp_prior_disaster_years = disasters_affected %>%   filter(year_declared %in% (cbp_df$year %>% unique())) %>%   distinct(year_declared)  cbp_affected %>%   filter(employees > 0, industry %in% top_8_industries) %>%   arrange(desc(employees)) %>%   ggplot(aes(x = year, y = employees, color = industry_label, group = industry_label)) +   geom_line() +   geom_vline(data = cbp_prior_disaster_years, color = \"grey\", linetype = \"dashed\", aes(xintercept = year_declared)) +   scale_y_continuous(labels = scales::comma) +   scale_x_continuous(n.breaks = length((cbp_df$year %>% unique()))) +   labs(y = \"Employees (n)\", x = \"\")"},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"small-businesses-over-time","dir":"Articles","previous_headings":"Section 1: The Affected County Baseline Profile","what":"Small Businesses over Time","title":"Economic Recovery Post Disaster","text":"Identify smaller businesses, may vulnerable disaster-related economic shocks.","code":"total_employers = cbp_affected %>%   filter(industry == \"total\", employee_size_range_label == \"All establishments\") %>%   slice_max(year) %>%   pull(employers)  cbp_affected %>%   tibble::as_tibble() %>%   filter(employee_size_range_label != \"All establishments\") %>%   mutate(     employee_size_range_label = case_when(       employee_size_range_label %in% c(\"<100-249 employees\", \"250-499 employees\") ~ \"100-499 employees\",       employee_size_range_label %in% c(\"500-999 employees\", \"1000+\") ~ \"500+ employees\",       TRUE ~ employee_size_range_label),     employee_size_range = factor(       employee_size_range_label,        levels = c(         \"1-4 employees\", \"<5 employees\", \"5-9 employees\", \"10-19 employees\", \"20-49 employees\",          \"50-99 employees\", \"100-499 employees\", \"500+ employees\"),          ordered = TRUE),     industry_label = factor(       industry_label,        levels = count(., industry_label, sort = TRUE) %>% pull(industry_label),       ordered = TRUE)) %>%   mutate(.by = industry, employer_total = sum(employers)) %>%   filter(employer_total > (.05 * total_employers)) %>%   ggplot(aes(x = year)) +     geom_area(aes(y = employers, fill = employee_size_range)) +     facet_wrap(~ reorder(industry_label, -employer_total), ncol = 4) +     labs(x = \"Year\", y = \"Employers\", title = \"Employers by Number of Employees, by Industry\") +     scale_y_continuous(labels = scales::comma)"},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"county-fiscal-capacity-over-time","dir":"Articles","previous_headings":"Section 1: The Affected County Baseline Profile","what":"County Fiscal Capacity Over Time","title":"Economic Recovery Post Disaster","text":"","code":"county_expenses = get_government_finances() finances_years = county_expenses %>% pull(year) %>% unique()  finances_prior_disaster_years = disasters_affected %>%   filter(year_declared %in% finances_years) %>%   distinct(year_declared)  county_expenses %>%   filter(GEOID %in% affected_county_fips) %>%   mutate(across(matches(\"revenue|expenditure\"), ~ .x / 1000)) %>%   pivot_longer(-c(year, GEOID, county_name)) %>%   filter(name %in% c(\"revenue_total\", \"expenditure_total\")) %>%   mutate(name = if_else(str_detect(name, \"expenditure\"), \"Expenditures\", \"Revenues\")) %>%   inflation_adjust(year_variable = \"year\", dollar_variables = \"value\", base_year = 2024, names_suffix = \"_adjusted\") %>%   ggplot(aes(x = year, y = value, color = name, group = name)) +     geom_line() +     geom_point() +     geom_vline(data = finances_prior_disaster_years, color = \"grey\", linetype = \"dashed\", aes(xintercept = year_declared)) +      scale_y_continuous(labels = scales::dollar_format(suffix = \"M\")) +     labs(x = \"Year\", y = \"USD (Millions)\")"},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"section-2-selecting-comparison-counties","dir":"Articles","previous_headings":"","what":"Section 2: Selecting Comparison Counties","title":"Economic Recovery Post Disaster","text":"Identify historical analogs: counties experienced similar disasters 5+ years ago.","code":""},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"assemble-matching-dataset","dir":"Articles","previous_headings":"Section 2: Selecting Comparison Counties","what":"Assemble Matching Dataset","title":"Economic Recovery Post Disaster","text":"Build county-level dataset variables needed matching.","code":"# Disaster history: count and binary indicators by hazard type in past 5 years disaster_lookback_years <- 5 reference_year <- disaster_year - 1  # Use year before disaster for matching  disaster_history <- disasters %>%   filter(     year_declared >= (reference_year - disaster_lookback_years),     year_declared <= reference_year) %>%   tidytable::summarise(     .by = GEOID,     n_disasters_prior_5yr = sum(incidents_natural_hazard, na.rm = TRUE),     fire_prior_5yr = as.integer(sum(incidents_fire, na.rm = TRUE) > 0),     flood_prior_5yr = as.integer(sum(incidents_flood, na.rm = TRUE) > 0),     hurricane_prior_5yr = as.integer(sum(incidents_hurricane, na.rm = TRUE) > 0),     severe_storm_prior_5yr = as.integer(sum(incidents_severe_storm, na.rm = TRUE) > 0),     tornado_prior_5yr = as.integer(sum(incidents_tornado, na.rm = TRUE) > 0),     winter_storm_prior_5yr = as.integer(sum(incidents_winter_storm, na.rm = TRUE) > 0),     drought_prior_5yr = as.integer(sum(incidents_drought, na.rm = TRUE) > 0)) %>%   as_tibble() sheldus_reference_year = if_else(reference_year < 2023, reference_year, 2023)  sheldus_matching = sheldus_df %>%   filter(year == sheldus_reference_year) # Industry employment shares from County Business Patterns # Use 2-digit NAICS codes for broad sector shares cbp_reference_year = if_else(reference_year < 2023, reference_year, 2023)  cbp_matching <- cbp_df %>%   ## filter out the employers by employee size records   filter(year == cbp_reference_year, employees > 0) %>%   mutate(GEOID = str_c(state, county)) %>%   select(GEOID, industry, employees) %>%   as_tibble()  # Calculate total employment per county cbp_totals <- cbp_matching %>%   filter(industry == \"total\") %>%   select(GEOID, total_employees = employees)  # Calculate employment share by industry industry_shares <- cbp_matching %>%   filter(industry != \"total\") %>%   tidylog::left_join(cbp_totals, by = \"GEOID\") %>%   arrange(GEOID) %>%   mutate(     share_employees_ = employees / total_employees,     industry_var = str_c(\"share_employees_\", industry)) %>%   select(GEOID, industry_var, share_employees_) %>%   pivot_wider(names_from = industry_var, values_from = share_employees_, values_fill = 0)  # Add total employment ## NOTE: the total employee count is always greater than or equal to  ## the sum of individual industries' employment countes because CBP omits ## some industry categories industry_matching <- industry_shares %>%   left_join(cbp_totals, by = \"GEOID\") # NFIP residential coverage rate by county nfip_matching <- get_nfip_residential_penetration() %>%   mutate(share_residential_structures_sfha = residential_structures_sfha / residential_structures) %>%   select(GEOID, share_residential_structures_sfha, penetration_rate_sfha) finance_reference_year = if_else(reference_year < 2023, reference_year, 2022)  # Total county government expenses county_finances_matching = county_expenses %>%   filter(year == finance_reference_year) # Sociodemographic characteristics from ACS acs_matching <- acs_df_2023 %>%   select(GEOID, all_of(acs_matching_variables)) # Combine all matching variables into single dataset matching_data <- acs_matching %>%   left_join(disaster_history, by = \"GEOID\") %>%   left_join(sheldus_matching, by = \"GEOID\") %>%   left_join(industry_matching, by = \"GEOID\") %>%   left_join(nfip_matching, by = \"GEOID\") %>%   left_join(county_finances_matching, by = \"GEOID\") %>%   # Replace NAs with 0 for disaster counts (counties with no disasters)   mutate(across(ends_with(\"_prior_5yr\"), ~ replace_na(.x, 0))) %>%   # Drop counties with missing core variables   filter(!is.na(total_population_universe), !is.na(total_employees))"},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"select-comparison-counties","dir":"Articles","previous_headings":"Section 2: Selecting Comparison Counties","what":"Select Comparison Counties","title":"Economic Recovery Post Disaster","text":"","code":"# Hard filter: same disaster type, disaster occurred 5+ years ago comparison_pool <- disasters %>%   filter(     year_declared <= 2021,  # Enough post-period     year_declared >= 2018) %>%   slice(.by = GEOID, 1) %>%   distinct(GEOID, year_declared) %>%   rename(comparison_disaster_year = year_declared)  # Get affected county's characteristics affected_county_chars <- matching_data %>%   filter(GEOID == affected_county_fips)  # Join matching data comparison_candidates <- comparison_pool %>%   inner_join(matching_data, by = \"GEOID\") %>%   filter(     total_population_universe > affected_county_chars$total_population_universe * .75,     total_population_universe < affected_county_chars$total_population_universe * 1.25,     median_household_income_universe_allraces > affected_county_chars$median_household_income_universe_allraces * .75,     median_household_income_universe_allraces < affected_county_chars$median_household_income_universe_allraces * 1.25,     GEOID != affected_county_fips)  # Exclude affected county # Calculate Mahalanobis distance to affected county  # Select numeric variables for distance calculation matching_vars <- c(   acs_matching_variables,   \"n_disasters_prior_5yr\",   \"total_employees\",   \"penetration_rate_sfha\",   \"revenue_total\",   \"expenditure_total\",   \"damage_property_millions\")  # Prepare matrices matrix_candidates <- comparison_candidates %>%   select(all_of(matching_vars)) %>%   as.matrix()  matrix_affected <- affected_county_chars %>%   select(all_of(matching_vars)) %>%   as.matrix()  # Calculate covariance matrix and Mahalanobis distance covariance_matrix <- cov(matrix_candidates, use = \"pairwise.complete.obs\") distances <- mahalanobis(matrix_candidates, center = matrix_affected, cov = covariance_matrix, tol=1e-30)  # Select top k nearest neighbors k_neighbors <- 10  comparison_counties <- comparison_candidates %>%   mutate(mahalanobis_distance = distances) %>%   slice_min(mahalanobis_distance, n = k_neighbors) %>%   select(GEOID, comparison_disaster_year, mahalanobis_distance) %>%   left_join(tidycensus::fips_codes %>% transmute(county, GEOID = str_c(state_code, county_code))) %>%   slice(1:5)"},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"section-3-event-study-data-preparation","dir":"Articles","previous_headings":"","what":"Section 3: Event-Study Data Preparation","title":"Economic Recovery Post Disaster","text":"Align outcome datasets event time (t=0 disaster year).","code":"# Create reference table: affected county + comparison counties with disaster years county_reference <- bind_rows(   # Affected county   tibble(     GEOID = affected_county_fips,     disaster_year_event = disaster_year,     county_type = \"affected\"),   # Comparison counties   comparison_counties %>%     transmute(       GEOID,       disaster_year_event = comparison_disaster_year,       county_type = \"comparison\"))  # Define event window event_window <- c(-5, 4) # Align to event time cbp_event_aligned <- cbp_df %>%   mutate(GEOID = str_c(state, county)) %>%   rename(calendar_year = year) %>%   inner_join(county_reference, by = \"GEOID\") %>%   mutate(event_time = calendar_year - disaster_year_event) %>%   filter(event_time >= event_window[1], event_time <= event_window[2]) %>%   select(GEOID, county_type, disaster_year_event, calendar_year, event_time,          industry, employees, employers, annual_payroll) # Align to event time fiscal_event_aligned <- county_expenses %>%   rename(calendar_year = year) %>%   inner_join(county_reference, by = \"GEOID\") %>%   mutate(event_time = calendar_year - disaster_year_event) %>%   filter(event_time >= event_window[1], event_time <= event_window[2]) %>%   select(GEOID, county_type, disaster_year_event, calendar_year, event_time,          expenditure_total, revenue_total) # SBA disaster loans sba_raw <- get_sba_loans()  sba_crosswalk = get_crosswalk(   source_geography = \"zcta\",   target_geography = \"county\")  sba_simple = sba_raw %>%   select(     source_geoid = damaged_property_zip_code,     sba_loan_amount = approved_amount_total,     loan_type,     fiscal_year)  warning(\"The crosswalking is imperfect and fiscal and calendar years are not aligned.\") sba_county = sba_simple %>%   tidylog::left_join(sba_crosswalk$crosswalks$step_1, by = \"source_geoid\") %>%   mutate(target_geoid = str_c(state_fips, target_geoid)) %>%   tidytable::summarize(     .by = c(target_geoid, loan_type, fiscal_year),     sba_loan_amount = sum(sba_loan_amount * allocation_factor_source_to_target)) %>%   filter(!is.na(target_geoid)) %>%   mutate(     GEOID = target_geoid,      calendar_year = fiscal_year %>% as.numeric) %>%   pivot_wider(names_from = loan_type, values_from = sba_loan_amount) %>%   rename(business_loan = business, residential_loan = residential) %>%   mutate(across(matches(\"loan\"), ~ if_else(is.na(.x), 0, .x)))  # Align to event time sba_event_aligned <- sba_county %>%   inner_join(county_reference, by = \"GEOID\") %>%   mutate(event_time = calendar_year - disaster_year_event) %>%   filter(event_time >= event_window[1], event_time <= event_window[2]) %>%   select(GEOID, county_type, disaster_year_event, calendar_year, event_time,          matches(\"loan\")) # FEMA Public Assistance pa_raw <- get_public_assistance() #>  Processed 360244 groups out of 656351. 55% done. Time elapsed: 3s. ETA: 2s. Processed 550614 groups out of 656351. 84% done. Time elapsed: 4s. ETA: 0s. Processed 656351 groups out of 656351. 100% done. Time elapsed: 4s. ETA: 0s.  # Aggregate to county-year level pa_county_year <- pa_raw %>%   mutate(     GEOID = county_fips,     calendar_year = declaration_year) %>%   summarise(     .by = c(GEOID, calendar_year),     across(.cols = matches(\"split\"), ~ sum(.x, na.rm = TRUE)))  # Align to event time pa_event_aligned <- pa_county_year %>%   inner_join(county_reference, by = \"GEOID\") %>%   mutate(event_time = calendar_year - disaster_year_event) %>%   filter(event_time >= event_window[1], event_time <= event_window[2]) %>%   select(GEOID, county_type, disaster_year_event, calendar_year, event_time,          pa_federal_funding_obligated_split) # FEMA Individual and Households Program # ihp_raw <- get_ihp_registrations()  # # Aggregate to county-year level # ihp_county_year <- ihp_raw %>% #   mutate(calendar_year = lubridate::year(declaration_date)) %>% #   summarise( #     .by = c(GEOID, calendar_year), #     ihp_registrations_n = n(), #     ihp_approved_n = sum(ihp_eligible, na.rm = TRUE), #     ihp_amount_total = sum(ihp_amount, na.rm = TRUE), #     ihp_ha_amount = sum(ha_amount, na.rm = TRUE), #     ihp_ona_amount = sum(ona_amount, na.rm = TRUE))  # # Align to event time # ihp_event_aligned <- ihp_county_year %>% #   inner_join(county_reference, by = \"GEOID\") %>% #   mutate(event_time = calendar_year - disaster_year_event) %>% #   filter(event_time >= event_window[1], event_time <= event_window[2]) %>% #   select(GEOID, county_type, disaster_year_event, calendar_year, event_time, #          ihp_registrations_n, ihp_approved_n, ihp_amount_total, ihp_ha_amount, ihp_ona_amount)"},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"section-4-employment-trajectories-event-study-style","dir":"Articles","previous_headings":"","what":"Section 4: Employment Trajectories (Event-Study Style)","title":"Economic Recovery Post Disaster","text":"Plot employment trends time relative disaster (t=0). Affected county: t-6 t=0 (present) Comparison counties: full t-6 t+6 window, aligned disaster year","code":"# Total employment over event time cbp_event_aligned %>%   filter(industry == \"total\", employees > 0) %>%   tibble::as_tibble() %>%   ggplot(aes(x = event_time, y = employees, group = GEOID, color = county_type, linetype = county_type)) +   geom_line() +   geom_point() +   ylim(c(0, NA)) +   geom_vline(xintercept = 0, linetype = \"dashed\", color = \"grey40\") +   scale_y_continuous(labels = scales::comma) +   scale_color_manual(values = c(\"affected\" = \"#1696d2\", \"comparison\" = \"#d2d2d2\")) +   labs(     x = \"Years Relative to Disaster (t=0)\",     y = \"Total Employees\",     title = \"Employment Trajectory: Affected vs. Comparison Counties\") +   theme(legend.position = \"none\")"},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"section-5-local-government-fiscal-trajectories-event-study-style","dir":"Articles","previous_headings":"","what":"Section 5: Local Government Fiscal Trajectories (Event-Study Style)","title":"Economic Recovery Post Disaster","text":"Examine local government finances evolved comparison counties post-disaster.","code":"# Total county expenses over event time fiscal_event_aligned %>%   mutate(county_type = if_else(str_detect(county_type, \"affected\"), \"Impacted\", \"Comparison\")) %>%   ggplot(aes(x = event_time, y = expenditure_total / 1000, group = GEOID, color = county_type)) +   geom_line() +   geom_point() +   geom_vline(xintercept = 0, linetype = \"dashed\", color = \"grey40\") +   scale_y_continuous(labels = scales::dollar_format(suffix = \"M\")) +   ylim(c(0, NA)) +   scale_color_manual(values = c(\"Impacted\" = \"#1696d2\", \"Comparison\" = \"#d2d2d2\")) +   labs(     x = \"Years Relative to Disaster (t=0)\",     y = \"Total County Expenses (Millions)\",     title = \"County Government Expenses: Affected vs. Comparison Counties\") +   theme(legend.position = \"none\") # Total county expenses over event time fiscal_event_aligned %>%   mutate(county_type = if_else(str_detect(county_type, \"affected\"), \"Impacted\", \"Comparison\")) %>%   ggplot(aes(x = event_time, y = revenue_total / 1000, group = GEOID, color = county_type)) +   geom_line() +   geom_point() +   geom_vline(xintercept = 0, linetype = \"dashed\", color = \"grey40\") +   scale_y_continuous(labels = scales::dollar_format(suffix = \"M\")) +   scale_color_manual(values = c(\"Impacted\" = \"#1696d2\", \"Comparison\" = \"#d2d2d2\")) +   labs(     x = \"Years Relative to Disaster (t=0)\",     y = \"Total County Revenues (Millions)\",     title = \"County Government Revenues: Affected vs. Comparison Counties\") +   theme(legend.position = \"none\")"},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"section-6-recovery-resources-in-comparison-cases","dir":"Articles","previous_headings":"","what":"Section 6: Recovery Resources in Comparison Cases","title":"Economic Recovery Post Disaster","text":"Describe typical federal assistance flows based historical analogs. Since affected county’s disaster just occurred, show comparison counties’ post-disaster resource flows projections.","code":""},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"sba-disaster-loans","dir":"Articles","previous_headings":"Section 6: Recovery Resources in Comparison Cases","what":"SBA Disaster Loans","title":"Economic Recovery Post Disaster","text":"","code":"# SBA loans over event time (comparison counties only for post-period)  sba_event_aligned %>%   arrange(GEOID, event_time) %>%   mutate(     .by = GEOID,     across(matches(\"loan\"), ~ cumsum(.x))) %>%   mutate(county_type = if_else(str_detect(county_type, \"affected\"), \"Impacted\", \"Comparison\")) %>%   ggplot(aes(x = event_time, y = residential_loan / 1000000, group = GEOID, color = county_type)) +   geom_line() +   ylim(c(0, NA)) +   geom_vline(xintercept = 0, linetype = \"dashed\", color = \"grey40\") +   scale_y_continuous(labels = scales::dollar_format(suffix = \"M\")) +   scale_color_manual(values = c(\"Impacted\" = \"#1696d2\", \"Comparison\" = \"#d2d2d2\")) +   labs(     x = \"Years relative to disaster (t=0)\",     y = \"SBA loans (cumulative)\",     title = \"Cumulative SBA Loans - Residential\") +   theme(legend.position = \"none\") sba_event_aligned %>%   arrange(GEOID, event_time) %>%   mutate(     .by = GEOID,     across(matches(\"loan\"), ~ cumsum(.x))) %>%   ggplot(aes(x = event_time, y = business_loan / 1000000, group = GEOID, color = county_type)) +   geom_line() +   geom_vline(xintercept = 0, linetype = \"dashed\", color = \"grey40\") +   scale_y_continuous(labels = scales::dollar_format(suffix = \"M\")) +   scale_color_manual(values = c(\"affected\" = \"#1696d2\", \"comparison\" = \"#d2d2d2\")) +   labs(     x = \"Years relative to disaster (t=0)\",     y = \"SBA loans (cumulative)\",     title = \"Cumulative SBA Loans - Business\") +   theme(legend.position = \"none\")"},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"fema-public-assistance","dir":"Articles","previous_headings":"Section 6: Recovery Resources in Comparison Cases","what":"FEMA Public Assistance","title":"Economic Recovery Post Disaster","text":"","code":"# PA funding over event time (comparison counties only for post-period) pa_event_aligned %>%   mutate(county_type = if_else(str_detect(county_type, \"affected\"), \"Impacted\", \"Comparison\")) %>%   ggplot(aes(x = event_time, y = pa_federal_funding_obligated_split / 1e6, group = GEOID, color = county_type)) +   geom_line() +   geom_vline(xintercept = 0, linetype = \"dashed\", color = \"grey40\") +   scale_y_continuous(labels = scales::dollar_format(suffix = \"M\")) +   scale_color_manual(values = c(\"Impacted\" = \"#1696d2\", \"Comparison\" = \"#d2d2d2\")) +   labs(     x = \"Years Relative to Disaster (t=0)\",     y = \"FEMA PA Federal Share Obligated (Millions)\",     title = \"FEMA Public Assistance in Comparison Counties\")"},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"individual-and-households-program","dir":"Articles","previous_headings":"Section 6: Recovery Resources in Comparison Cases","what":"Individual and Households Program","title":"Economic Recovery Post Disaster","text":"","code":"# # IHP funding over event time (comparison counties only for post-period) # ihp_event_aligned %>% #   ggplot(aes(x = event_time, y = ihp_amount_total / 1e6, group = GEOID)) + #   geom_line(alpha = 0.4, color = \"#d2d2d2\") + #   stat_summary(aes(group = 1), fun = median, geom = \"line\", color = \"#1696d2\", linewidth = 1.2) + #   geom_vline(xintercept = 0, linetype = \"dashed\", color = \"grey40\") + #   scale_y_continuous(labels = scales::dollar_format(suffix = \"M\")) + #   labs( #     x = \"Years Relative to Disaster (t=0)\", #     y = \"IHP Total Amount (Millions)\", #     title = \"FEMA Individual & Households Program in Comparison Counties\", #     subtitle = \"Blue line = median across comparison counties\" #   )"},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"section-7-key-takeaways","dir":"Articles","previous_headings":"","what":"Section 7: Key Takeaways","title":"Economic Recovery Post Disaster","text":"","code":"# Programmatically generate summary statistics for the factsheet: # - Pre-disaster vulnerability indicators for affected county # - Median/range of recovery trajectories from comparison counties # - Typical federal resource flows"},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"summary-table","dir":"Articles","previous_headings":"Section 7: Key Takeaways","what":"Summary Table","title":"Economic Recovery Post Disaster","text":"","code":"# Create summary table of key indicators"},{"path":[]},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"comparison-county-selection-criteria","dir":"Articles","previous_headings":"Section 7: Key Takeaways > Technical Notes","what":"Comparison County Selection Criteria","title":"Economic Recovery Post Disaster","text":"Similar population size income (within 25% affected county either direction)","code":""},{"path":"https://ui-research.github.io/climateapi/articles/economic_recovery_factsheet.html","id":"data-availability-notes","dir":"Articles","previous_headings":"Section 7: Key Takeaways > Technical Notes","what":"Data Availability Notes","title":"Economic Recovery Post Disaster","text":"LODES data typically lag 2 years County Business Patterns lag 2 years Government finances lag 2 FEMA assistance data near real-time","code":""},{"path":"https://ui-research.github.io/climateapi/articles/get_sheldus.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"SHELDUS Hazard Data","text":"get_sheldus() function provides access county-level hazard event data Spatial Hazard Events Losses Database United States (SHELDUS). database tracks property damage, crop damage, fatalities, injuries natural hazards across US counties.","code":""},{"path":"https://ui-research.github.io/climateapi/articles/get_sheldus.html","id":"data-source","dir":"Articles","previous_headings":"","what":"Data source","title":"SHELDUS Hazard Data","text":"SHELDUS maintained Arizona State University’s Center Emergency Management Homeland Security. database compiles hazard event data multiple sources including NOAA Storm Events, National Climatic Data Center, federal agencies. Access SHELDUS requires subscription. See https://cemhs.asu.edu/sheldus information.","code":""},{"path":"https://ui-research.github.io/climateapi/articles/get_sheldus.html","id":"loading-the-data","dir":"Articles","previous_headings":"","what":"Loading the data","title":"SHELDUS Hazard Data","text":"","code":"library(climateapi) library(tidyverse) library(sf) library(urbnthemes)  set_urbn_defaults(style = \"print\") sheldus <- get_sheldus()"},{"path":"https://ui-research.github.io/climateapi/articles/get_sheldus.html","id":"data-structure","dir":"Articles","previous_headings":"","what":"Data structure","title":"SHELDUS Hazard Data","text":"row represents unique combination county, year, month, hazard type. county-month-hazard combinations recorded events included. Key variables include: unique_id: Unique identifier observation GEOID: Five-digit county FIPS code year month: Temporal identifiers hazard: Type hazard event (e.g., “Flooding”, “Hurricane/Tropical Storm”) damage_property: Property damage 2023 inflation-adjusted dollars damage_crop: Crop damage 2023 inflation-adjusted dollars fatalities injuries: Human impacts records: Number individual events aggregated observation","code":"glimpse(sheldus) #> Rows: 1,000,189 #> Columns: 13 #> $ unique_id         <chr> \"199da95a-821f-4f2f-974a-85bb0c4e8a0f\", \"a9af66c4-1ea9-4c43-9a7e-85211bf280db\", \"b6e481a5-998b-46a3-a393-0064de9e87b4\", \"e40fd03d-cabf-4e41-9… #> $ GEOID             <chr> \"01001\", \"01001\", \"01001\", \"01001\", \"01001\", \"01001\", \"01001\", \"01001\", \"01001\", \"01001\", \"01001\", \"01001\", \"01001\", \"01001\", \"01001\", \"01001… #> $ state_name        <chr> \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\"… #> $ county_name       <chr> \"Autauga\", \"Autauga\", \"Autauga\", \"Autauga\", \"Autauga\", \"Autauga\", \"Autauga\", \"Autauga\", \"Autauga\", \"Autauga\", \"Autauga\", \"Autauga\", \"Autauga\"… #> $ year              <dbl> 1961, 1961, 1961, 1962, 1962, 1962, 1962, 1962, 1963, 1963, 1963, 1964, 1964, 1965, 1966, 1967, 1968, 1968, 1968, 1969, 1969, 1969, 1969, 196… #> $ month             <dbl> 1, 2, 12, 1, 4, 4, 4, 12, 1, 4, 12, 4, 4, 7, 1, 3, 3, 8, 8, 3, 3, 6, 6, 6, 4, 4, 4, 5, 1, 3, 3, 4, 4, 4, 5, 5, 5, 6, 3, 3, 2, 4, 5, 11, 1, 2,… #> $ hazard            <chr> \"Winter Weather\", \"Severe Storm/Thunder Storm\", \"Severe Storm/Thunder Storm\", \"Winter Weather\", \"Hail\", \"Severe Storm/Thunder Storm\", \"Wind\",… #> $ damage_property   <dbl> 21498.713, 75141.081, 83907.468, 74394.646, 2479.825, 2479.825, 2479.825, 74394.646, 73422.069, 491928.296, 73422.167, 292024.963, 6389.224, … #> $ damage_crop       <dbl> 7514.11815, 75141.08081, 8390.71660, 74394.64644, 2479.82487, 2479.82487, 2479.82487, 74394.64644, 73422.06910, 0.00000, 7342.22659, 34952.83… #> $ fatalities        <dbl> 0.00, 0.00, 0.00, 0.06, 0.00, 0.00, 0.00, 0.04, 0.00, 0.00, 0.00, 0.00, 0.00, 1.00, 0.15, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.0… #> $ injuries          <dbl> 0.00000, 0.00000, 0.00000, 0.00000, 0.00333, 0.00333, 0.00333, 0.00000, 0.00000, 0.00000, 0.00000, 0.04000, 0.04000, 0.00000, 0.07000, 0.0000… #> $ records           <dbl> 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, … #> $ allocation_factor <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…"},{"path":[]},{"path":"https://ui-research.github.io/climateapi/articles/get_sheldus.html","id":"hazard-types-in-the-database","dir":"Articles","previous_headings":"Example analyses","what":"Hazard types in the database","title":"SHELDUS Hazard Data","text":"","code":"sheldus |>   distinct(hazard) |>   arrange(hazard) |>   pull(hazard) #>  [1] \"Avalanche\"                  \"Coastal\"                    \"Drought\"                    \"Earthquake\"                 \"Flooding\"                   #>  [6] \"Fog\"                        \"Hail\"                       \"Heat\"                       \"Hurricane/Tropical Storm\"   \"Landslide\"                  #> [11] \"Lightning\"                  \"Severe Storm/Thunder Storm\" \"Tornado\"                    \"Tsunami/Seiche\"             \"Volcano\"                    #> [16] \"Wildfire\"                   \"Wind\"                       \"Winter Weather\""},{"path":"https://ui-research.github.io/climateapi/articles/get_sheldus.html","id":"annual-property-damage-by-hazard-type","dir":"Articles","previous_headings":"Example analyses","what":"Annual property damage by hazard type","title":"SHELDUS Hazard Data","text":"","code":"df1 <- sheldus |>   summarize(     .by = c(year, hazard),     total_damage = sum(damage_property, na.rm = TRUE) / 1e9)  top_hazards <- df1 |>   summarize(     .by = hazard,     total = sum(total_damage, na.rm = TRUE)) |>   slice_max(total, n = 5) |>   pull(hazard)  df1 |>   filter(hazard %in% top_hazards) |>   ggplot(aes(x = year, y = total_damage, fill = hazard)) +   geom_col() +   scale_fill_manual(values = c(     palette_urbn_main[1:4], palette_urbn_cyan[5])) +   labs(     title = \"Annual Property Damage by Hazard Type\",     subtitle = \"Top 5 hazard types by total damage, 2023 dollars\",     x = \"\",     y = \"Property damage (billions)\",     fill = \"Hazard type\")"},{"path":"https://ui-research.github.io/climateapi/articles/get_sheldus.html","id":"geographic-distribution-of-flood-damage","dir":"Articles","previous_headings":"Example analyses","what":"Geographic distribution of flood damage","title":"SHELDUS Hazard Data","text":"","code":"flood_damage <- sheldus |>   filter(hazard == \"Flooding\") |>   summarize(     .by = GEOID,     total_damage = sum(damage_property, na.rm = TRUE))  counties_sf <- tigris::counties(cb = TRUE, year = 2022, progress_bar = FALSE) |>   st_transform(5070) |>   filter(!STATEFP %in% c(\"02\", \"15\", \"72\", \"78\", \"66\", \"60\", \"69\"))  flood_map <- counties_sf |>   left_join(flood_damage, by = \"GEOID\") |>   mutate(     damage_category = case_when(       is.na(total_damage) | total_damage == 0 ~ \"No recorded damage\",       total_damage < 1e6 ~ \"< $1M\",       total_damage < 10e6 ~ \"$1M - $10M\",       total_damage < 100e6 ~ \"$10M - $100M\",       TRUE ~ \"> $100M\"),     damage_category = factor(       damage_category,       levels = c(\"No recorded damage\", \"< $1M\", \"$1M - $10M\", \"$10M - $100M\", \"> $100M\")))  ggplot(flood_map) +   geom_sf(aes(fill = damage_category), color = NA) +   scale_fill_manual(values = c(     \"No recorded damage\" = \"grey90\",     \"< $1M\" = palette_urbn_cyan[1],     \"$1M - $10M\" = palette_urbn_cyan[3],     \"$10M - $100M\" = palette_urbn_cyan[5],     \"> $100M\" = palette_urbn_cyan[7])) +   labs(     title = \"Cumulative Flood Damage by County\",     subtitle = \"Total property damage from flooding events, 2023 dollars\",     fill = \"Total damage\") +   theme_urbn_map()"},{"path":"https://ui-research.github.io/climateapi/articles/get_sheldus.html","id":"seasonal-patterns-in-hazard-events","dir":"Articles","previous_headings":"Example analyses","what":"Seasonal patterns in hazard events","title":"SHELDUS Hazard Data","text":"","code":"seasonal <- sheldus |>   filter(hazard %in% top_hazards) |>   summarize(     .by = c(month, hazard),     total_events = sum(records, na.rm = TRUE))  ggplot(seasonal, aes(x = month, y = total_events, color = hazard)) +   geom_line(linewidth = 1) +   geom_point(size = 2) +   scale_x_continuous(breaks = 1:12, labels = month.abb) +   scale_color_manual(values = c(     palette_urbn_main[1:4], palette_urbn_cyan[5])) +   labs(     title = \"Seasonal Distribution of Hazard Events\",     subtitle = \"Total event count by month across all years\",     x = \"\",     y = \"Number of events\",     color = \"Hazard type\")"},{"path":"https://ui-research.github.io/climateapi/articles/get_sheldus.html","id":"counties-with-highest-fatalities","dir":"Articles","previous_headings":"Example analyses","what":"Counties with highest fatalities","title":"SHELDUS Hazard Data","text":"","code":"high_fatality_counties <- sheldus |>   summarize(     .by = c(GEOID, state_name, county_name),     total_fatalities = sum(fatalities, na.rm = TRUE)) |>   slice_max(total_fatalities, n = 15)  high_fatality_counties |>   mutate(     county_label = str_c(county_name, \", \", state_name),     county_label = fct_reorder(county_label, total_fatalities)) |>   ggplot(aes(y = county_label, x = total_fatalities)) +   geom_col() +   labs(     title = \"Counties with Highest Hazard-Related Fatalities\",     x = \"Total fatalities\",     y = \"\")"},{"path":"https://ui-research.github.io/climateapi/articles/get_sheldus.html","id":"linking-with-census-data","dir":"Articles","previous_headings":"Example analyses","what":"Linking with census data","title":"SHELDUS Hazard Data","text":"county-level structure makes straightforward join demographic data.","code":"county_demographics <- tidycensus::get_acs(   geography = \"county\",   variables = c(     median_income = \"B19013_001\",     total_pop = \"B01003_001\"),   year = 2022,   output = \"wide\")  county_hazard_summary <- sheldus |>   filter(year >= 2018) |>   summarize(     .by = GEOID,     total_damage = sum(damage_property, na.rm = TRUE),     total_events = sum(records, na.rm = TRUE)) |>   left_join(county_demographics, by = \"GEOID\") |>   mutate(damage_per_capita = total_damage / total_popE)"},{"path":"https://ui-research.github.io/climateapi/articles/get_sheldus.html","id":"see-also","dir":"Articles","previous_headings":"","what":"See also","title":"SHELDUS Hazard Data","text":"get_fema_disaster_declarations(): FEMA disaster declarations get_nfip_claims(): National Flood Insurance Program claims data get_wildfire_burn_zones(): Wildfire burn zone disasters","code":""},{"path":"https://ui-research.github.io/climateapi/articles/get_structures.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"USA Structures Data","text":"get_structures() function retrieves building footprint data USA Structures dataset summarizes structure counts type tract county level. useful estimating number types buildings within areas affected natural hazards.","code":""},{"path":"https://ui-research.github.io/climateapi/articles/get_structures.html","id":"data-source","dir":"Articles","previous_headings":"","what":"Data source","title":"USA Structures Data","text":"Data sourced USA Structures dataset maintained Department Homeland Security. dataset contains building footprints derived high-resolution imagery structures across United States. See https://geoplatform.gov/metadata/9d4a3ae3-8637-4707-92a7-b7d67b769a6b information.","code":""},{"path":"https://ui-research.github.io/climateapi/articles/get_structures.html","id":"loading-the-data","dir":"Articles","previous_headings":"","what":"Loading the data","title":"USA Structures Data","text":"function requires boundaries argument specifying geographic area interest. must spatial polygon object defined coordinate reference system.","code":"library(climateapi) library(tidyverse) library(sf) library(urbnthemes)  set_urbn_defaults(style = \"print\") # Example: Get structures in Washington, DC dc_boundary <- tigris::states(cb = TRUE) |>   filter(STUSPS == \"DC\")  dc_structures <- get_structures(   boundaries = dc_boundary,   geography = \"tract\") #> Reading layer `DC_Structures' from data source  #>   `C:\\Users\\WCurranGroome\\Box\\METRO Climate and Communities Practice Area\\github-repository\\built-environment\\housing-units\\usa-structures\\raw\\DC\\DC_Structures.gdb'  #>   using driver `OpenFileGDB' #> Simple feature collection with 64701 features and 33 fields #> Geometry type: MULTIPOLYGON #> Dimension:     XY #> Bounding box:  xmin: -77.11509 ymin: 38.79307 xmax: -76.90971 ymax: 38.99554 #> Geodetic CRS:  WGS 84"},{"path":"https://ui-research.github.io/climateapi/articles/get_structures.html","id":"function-parameters","dir":"Articles","previous_headings":"","what":"Function parameters","title":"USA Structures Data","text":"boundaries: POLYGON MULTIPOLYGON sf object, sf::st_bbox()-style bounding box. Must defined CRS. geography: desired output geography. One \"tract\" \"county\". keep_structures: TRUE, returns summarized counts raw point-level structure data.","code":""},{"path":"https://ui-research.github.io/climateapi/articles/get_structures.html","id":"data-structure","dir":"Articles","previous_headings":"","what":"Data structure","title":"USA Structures Data","text":"row represents unique combination geographic unit (tract county) structure type. Key variables include: GEOID: Census tract (11-digit) county (5-digit) FIPS code primary_occupancy: primary use structure (e.g., “Residential”, “Commercial”) occupancy_class: Broader classification occupancy type count: Number structures type geographic unit","code":"glimpse(dc_structures) #> Rows: 1,951 #> Columns: 4 #> $ GEOID             <chr> \"11001000101\", \"11001000101\", \"11001000101\", \"11001000101\", \"11001000101\", \"11001000101\", \"11001000102\", \"11001000102\", \"11001000102\", \"11001… #> $ primary_occupancy <chr> \"Single Family Dwelling\", \"Multi - Family Dwelling\", \"Religious\", \"Retail Trade\", \"General Services\", \"Temporary Lodging\", \"Single Family Dwe… #> $ occupancy_class   <chr> \"Residential\", \"Residential\", \"Assembly\", \"Commercial\", \"Government\", \"Residential\", \"Residential\", \"Residential\", \"Commercial\", \"Commercial\"… #> $ count             <int> 63, 24, 5, 4, 1, 1, 384, 48, 42, 21, 19, 15, 13, 10, 8, 5, 5, 4, 2, 1, 1, 53, 8, 8, 1, 1, 1, 310, 60, 42, 23, 12, 9, 8, 7, 3, 3, 3, 3, 2, 2, …"},{"path":"https://ui-research.github.io/climateapi/articles/get_structures.html","id":"occupancy-types","dir":"Articles","previous_headings":"Data structure","what":"Occupancy types","title":"USA Structures Data","text":"","code":"dc_structures |>   distinct(occupancy_class, primary_occupancy) |>   arrange(occupancy_class, primary_occupancy) #> # A tibble: 27 × 2 #>    occupancy_class primary_occupancy               #>    <chr>           <chr>                           #>  1 Assembly        Indoor Arena                    #>  2 Assembly        Religious                       #>  3 Commercial      Entertainment and Recreation    #>  4 Commercial      Hospital                        #>  5 Commercial      Medical Office/Clinic           #>  6 Commercial      Parking                         #>  7 Commercial      Personal and Repair Services    #>  8 Commercial      Professional/Technical Services #>  9 Commercial      Retail Trade                    #> 10 Commercial      Theaters                        #> # ℹ 17 more rows"},{"path":[]},{"path":"https://ui-research.github.io/climateapi/articles/get_structures.html","id":"structure-composition-by-tract","dir":"Articles","previous_headings":"Example analyses","what":"Structure composition by tract","title":"USA Structures Data","text":"","code":"dc_summary <- dc_structures |>   summarize(     .by = GEOID,     total_structures = sum(count, na.rm = TRUE),     residential = sum(count[occupancy_class == \"Residential\"], na.rm = TRUE),     commercial = sum(count[occupancy_class == \"Commercial\"], na.rm = TRUE)) |>   mutate(     residential_share = residential / total_structures)  dc_summary |>   ggplot(aes(x = total_structures, y = residential_share)) +   geom_point(alpha = 0.7) +   scale_y_continuous(labels = scales::percent) +   labs(     title = \"Residential Share vs. Total Structures by Tract\",     subtitle = \"Washington, DC census tracts\",     x = \"Total structures\",     y = \"Share residential\")"},{"path":"https://ui-research.github.io/climateapi/articles/get_structures.html","id":"mapping-structure-density","dir":"Articles","previous_headings":"Example analyses","what":"Mapping structure density","title":"USA Structures Data","text":"","code":"dc_tracts <- tigris::tracts(state = \"DC\", cb = TRUE, year = 2023, progress_bar = FALSE) |>   st_transform(5070)  dc_tract_totals <- dc_structures |>   summarize(     .by = GEOID,     total_structures = sum(count, na.rm = TRUE))  dc_map <- dc_tracts |>   left_join(dc_tract_totals, by = \"GEOID\")  ggplot(dc_map) +   geom_sf(aes(fill = total_structures), color = \"white\", linewidth = 0.2) +   scale_fill_gradientn(     colors = c(palette_urbn_cyan[1], palette_urbn_cyan[4], palette_urbn_cyan[7]),     labels = scales::comma) +   labs(     title = \"Structure Count by Census Tract\",     subtitle = \"Washington, DC\",     fill = \"Structures\") +   theme_urbn_map()"},{"path":"https://ui-research.github.io/climateapi/articles/get_structures.html","id":"analyzing-structures-in-a-disaster-area","dir":"Articles","previous_headings":"Example analyses","what":"Analyzing structures in a disaster area","title":"USA Structures Data","text":"common use case estimating structures within hazard-affected area. example shows combine structure data wildfire burn zones.","code":"# Get a specific wildfire's burn zone burn_zones <- get_wildfire_burn_zones()  camp_fire <- burn_zones |>   filter(str_detect(wildfire_name, \"CAMP\"))  # Get structures within the burn zone camp_fire_structures <- get_structures(    boundaries = camp_fire,   geography = \"tract\",   keep_structures = TRUE)  # Summarized counts camp_fire_structures$structures_summarized |>   summarize(     .by = occupancy_class,     total = sum(count, na.rm = TRUE)) |>   arrange(desc(total))"},{"path":"https://ui-research.github.io/climateapi/articles/get_structures.html","id":"working-with-raw-structure-data","dir":"Articles","previous_headings":"Example analyses","what":"Working with raw structure data","title":"USA Structures Data","text":"Setting keep_structures = TRUE returns summarized data raw point-level structure data.","code":"dc_full <- get_structures(   boundaries = dc_boundary,   geography = \"county\",   keep_structures = TRUE)  # Access the raw point data raw_structures <- dc_full$structures_raw  # Access the summarized data summary_structures <- dc_full$structures_summarized  # Map individual structures ggplot() +   geom_sf(data = dc_boundary, fill = \"grey95\") +   geom_sf(     data = raw_structures |> filter(primary_occupancy == \"Commercial\"),     size = 0.1,     alpha = 0.5) +   labs(title = \"Commercial Structures in Washington, DC\") +   theme_urbn_map()"},{"path":"https://ui-research.github.io/climateapi/articles/get_structures.html","id":"county-level-analysis","dir":"Articles","previous_headings":"Example analyses","what":"County-level analysis","title":"USA Structures Data","text":"larger areas, county-level aggregation provides useful summary.","code":"# Get structures for multiple states southeast_boundary <- tigris::states(cb = TRUE) |>   filter(STUSPS %in% c(\"FL\", \"GA\", \"AL\", \"SC\"))  southeast_structures <- get_structures(   boundaries = southeast_boundary,   geography = \"county\")  # Summarize by county county_totals <- southeast_structures |>   summarize(     .by = GEOID,     total_structures = sum(count, na.rm = TRUE))"},{"path":"https://ui-research.github.io/climateapi/articles/get_structures.html","id":"performance-considerations","dir":"Articles","previous_headings":"","what":"Performance considerations","title":"USA Structures Data","text":"raw building footprint data files large. Processing can slow, especially multi-state analyses. Consider: Starting small geographic area test workflow Using county-level aggregation tract-level detail required Caching results repeated analyses","code":""},{"path":"https://ui-research.github.io/climateapi/articles/get_structures.html","id":"see-also","dir":"Articles","previous_headings":"","what":"See also","title":"USA Structures Data","text":"get_wildfire_burn_zones(): Wildfire burn zone disasters use boundaries get_current_fire_perimeters(): Active wildfire perimeters use boundaries get_fema_disaster_declarations(): FEMA disaster declarations","code":""},{"path":"https://ui-research.github.io/climateapi/articles/get_wildfire_burn_zones.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Wildfire Burn Zones","text":"get_wildfire_burn_zones() function provides access harmonized dataset wildfire burn zone disasters United States 2000-2025.","code":""},{"path":"https://ui-research.github.io/climateapi/articles/get_wildfire_burn_zones.html","id":"data-sources-and-methodology","dir":"Articles","previous_headings":"","what":"Data sources and methodology","title":"Wildfire Burn Zones","text":"dataset combines six authoritative wildfire data sources identify wildfires burned near communities resulted civilian fatalities, destroyed structures, received federal disaster relief. sources : FIRED (Fire Event Delineation): Satellite-derived fire perimeters MTBS (Monitoring Trends Burn Severity): Burn severity perimeters large fires NIFC (National Interagency Fire Center): Official fire incident data ICS-209 (Incident Status Summary): Incident management records RedBook: Historical wildfire statistics FEMA: Federal disaster declarations Wildfires classified “disasters” : Burned near community Civilian fatality Destroyed structure Federal disaster relief data described provided association journal article: Wilner, L.B., Piepmeier, L., Gordon, M. et al. Two half decades United States wildfire burn zone disaster data, 2000-2025. Sci Data 12, 1948 (2025). https://doi.org/10.1038/s41597-025-06226-8.","code":""},{"path":"https://ui-research.github.io/climateapi/articles/get_wildfire_burn_zones.html","id":"loading-the-data","dir":"Articles","previous_headings":"","what":"Loading the data","title":"Wildfire Burn Zones","text":"","code":"library(climateapi) library(tidyverse) library(sf) library(urbnthemes)  set_urbn_defaults(style = \"print\") burn_zones <- get_wildfire_burn_zones()"},{"path":"https://ui-research.github.io/climateapi/articles/get_wildfire_burn_zones.html","id":"data-structure","dir":"Articles","previous_headings":"","what":"Data structure","title":"Wildfire Burn Zones","text":"row dataset represents single wildfire burn zone disaster. Key variables include: wildfire_id: Unique identifier wildfire event year: Year wildfire occurred (2000-2025) wildfire_name: Name wildfire fire complex county_fips: Pipe-delimited string county FIPS codes affected counties county_name: Pipe-delimited string county names affected counties area_sq_km: Burned area square kilometers fatalities_total injuries_total: Human impacts structures_destroyed structures_threatened: Built environment impacts geometry: Burn zone polygon boundaries","code":"glimpse(burn_zones) #> Rows: 6,911 #> Columns: 18 #> $ wildfire_id                          <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,… #> $ id_fema                              <chr> NA, \"FM-5491-OK\", NA, NA, \"FM-5178-FL\", NA, NA, \"FM-5086-AZ\", NA, \"FM-5319-NV\", NA, NA, NA, NA, NA, \"FM-5445-CA\", NA, NA, … #> $ year                                 <int> 2018, 2024, 2017, 2014, 2017, 2019, 2016, 2015, 2017, 2020, 2020, 2014, 2017, 2016, 2022, 2022, 2022, 2020, 2022, 2020, 20… #> $ wildfire_name                        <chr> \"DONNELL\", \"57\", \"GARFIELD RD\", \"TYONEK\", \"30TH AVE\", \"G18\", \"WILLARD\", \"KEARNY RIV\", \"TURTLE\", \"NUMBERS\", \"LOYALTON\", \"FU… #> $ county_fips                          <chr> \"06003|06109\", \"40153\", \"12089\", \"02122\", \"12021\", \"08021\", \"06035\", \"04021\", \"30087\", \"32005\", \"06035|06063|06091\", \"0212… #> $ county_name                          <chr> \"ALPINE|TUOLUMNE\", \"WOODWARD\", \"NASSAU\", \"KENAI PENINSULA\", \"COLLIER\", \"CONEJOS\", \"LASSEN\", \"PINAL\", \"ROSEBUD\", \"DOUGLAS\",… #> $ area_sq_km                           <dbl> 146.200893, 19.105698, 2.921101, 6.714350, 26.204585, 9.151442, 11.433032, 6.250412, 6.634805, 75.963891, 183.863534, 779.… #> $ wildfire_complex_binary              <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… #> $ date_start                           <date> 2018-08-01, 2024-04-06, 2017-03-22, 2014-05-19, 2017-04-20, 2019-10-27, 2016-09-11, 2015-06-17, 2017-07-16, 2020-07-06, 2… #> $ date_containment                     <date> 2018-10-31, 2024-04-12, NA, NA, 2017-06-05, NA, 2016-10-12, 2015-06-27, NA, 2020-07-11, 2020-08-30, NA, 2017-07-18, NA, N… #> $ fatalities_total                     <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ injuries_total                       <int> 6, 2, NA, NA, 1, NA, NA, NA, NA, 2, NA, 4, NA, NA, NA, NA, NA, NA, 1, 2, 8, 20, NA, 5, 1, 2, 3, 2, NA, 6, NA, 1, NA, NA, N… #> $ structures_destroyed                 <int> 135, 1, 19, 5, 4, 4, 7, 3, 2, 40, 35, 4, 14, 1, 3, 194, 20, 9, 10, 1, 4, 247, 4, 24, 2, 20, 185, 30, 30, 4, NA, 1, 1, 5, 6… #> $ structures_threatened                <int> NA, 1720, NA, 0, 0, NA, NA, 50, 0, NA, NA, 0, 0, NA, NA, NA, 127, NA, 3, 0, 0, 0, 200, 0, 10, NA, NA, NA, 200, NA, NA, 16,… #> $ evacuation_total                     <int> NA, NA, NA, NA, 7000, 50, NA, NA, NA, 50, 0, NA, NA, NA, NA, NA, NA, 50, NA, NA, 30, 236, 411, 5122, 1200, 200, NA, 621, N… #> $ wui_type                             <chr> NA, NA, \"intermix\", NA, \"intermix\", \"intermix\", NA, \"interface|intermix\", \"intermix\", \"intermix\", \"intermix\", NA, \"intermi… #> $ density_people_sq_km_wildfire_buffer <dbl> 0.0743354479, 4.1285729324, 5.4731167321, 0.0562439821, 116.3346681161, 2.7371345095, 8.8706970226, 1.6293691415, 0.536265… #> $ geometry                             <GEOMETRY [m]> POLYGON ((-2033577 1961695,..., POLYGON ((-302378.6 1470132..., POLYGON ((1335180 915158.5,..., POLYGON ((-316073…"},{"path":[]},{"path":"https://ui-research.github.io/climateapi/articles/get_wildfire_burn_zones.html","id":"annual-trends-in-wildfire-disasters","dir":"Articles","previous_headings":"Example analyses","what":"Annual trends in wildfire disasters","title":"Wildfire Burn Zones","text":"","code":"# Extract state FIPS from the first county in the pipe-delimited list df1 = burn_zones |>   st_drop_geometry() |>   mutate(state_fips = str_sub(county_fips, 1, 2)) |>   summarize(     .by = c(year, state_fips),     n_wildfires = n(),     total_area_sq_km = sum(area_sq_km, na.rm = TRUE),     total_structures_destroyed = sum(structures_destroyed, na.rm = TRUE)) |>   left_join(     tigris::fips_codes %>% distinct(state, state_code),     by = c(\"state_fips\" = \"state_code\"))  top_five_states = df1 %>%   arrange(desc(n_wildfires)) %>%   distinct(state) %>%   slice(1:5)  df1 %>%   filter(state %in% top_five_states$state) %>%   mutate(state = factor(state, levels = top_five_states %>% pull(state), ordered = TRUE)) %>%   ggplot(aes(x = year, y = n_wildfires)) +   geom_col() +   labs(     title = \"Many states frequently experience more than 50 wildfires per year\",     subtitle = \"Disasters defined as wildfires causing fatalities, structure loss, or federal relief\",     x = \"\",     y = \"Number of wildfires\") +   facet_wrap(~state)"},{"path":"https://ui-research.github.io/climateapi/articles/get_wildfire_burn_zones.html","id":"geographic-distribution-of-impacts","dir":"Articles","previous_headings":"Example analyses","what":"Geographic distribution of impacts","title":"Wildfire Burn Zones","text":"","code":"state_impacts <- burn_zones |>   st_drop_geometry() |>   mutate(state_fips = str_sub(county_fips, 1, 2)) |>   summarize(     .by = state_fips,     n_wildfires = n_distinct(wildfire_id),     total_structures_destroyed = sum(structures_destroyed, na.rm = TRUE),     total_fatalities = sum(fatalities_total, na.rm = TRUE)   ) |>   left_join(     tidycensus::fips_codes |>       distinct(state_code, state_name),     by = c(\"state_fips\" = \"state_code\")   ) |>   filter(!is.na(state_name))  state_impacts |>   slice_max(n_wildfires, n = 10) |>   mutate(state_name = fct_reorder(state_name, n_wildfires)) |>   ggplot(aes(y = state_name, x = n_wildfires)) +   geom_col() +   labs(     title = \"States with Most Wildfire Burn Zone Disasters (2000-2025)\",     x = \"Number of distinct wildfires\",     y = \"\"   )"},{"path":"https://ui-research.github.io/climateapi/articles/get_wildfire_burn_zones.html","id":"mapping-wildfire-burn-zones","dir":"Articles","previous_headings":"Example analyses","what":"Mapping wildfire burn zones","title":"Wildfire Burn Zones","text":"","code":"# Get wildfires from a recent year in California ca_2020_fires <- burn_zones |>   filter(str_detect(county_fips, \"^06\"), year == 2020)  # Get California counties for context ca_counties <- tigris::counties(state = \"CA\", cb = TRUE, year = 2022, progress_bar = FALSE) |>   st_transform(5070)  ggplot() +   geom_sf(data = ca_counties, fill = \"grey95\", color = \"grey70\") +   geom_sf(data = ca_2020_fires, aes(fill = structures_destroyed), alpha = 0.8) +   scale_fill_continuous(trans = \"reverse\") +   labs(     title = \"California Wildfire Burn Zone Disasters (2020)\",     subtitle = \"Burn zone perimeters colored by structures destroyed\",     fill = \"Structures\\ndestroyed\") +   theme_urbn_map()"},{"path":"https://ui-research.github.io/climateapi/articles/get_wildfire_burn_zones.html","id":"analyzing-structure-loss-severity","dir":"Articles","previous_headings":"Example analyses","what":"Analyzing structure loss severity","title":"Wildfire Burn Zones","text":"","code":"burn_zones |>   st_drop_geometry() |>   distinct(wildfire_id, year, wildfire_name, structures_destroyed) |>   filter(!is.na(structures_destroyed), structures_destroyed > 0) |>   mutate(     severity = case_when(       structures_destroyed >= 1000 ~ \"1,000+ structures\",       structures_destroyed >= 100 ~ \"100-999\",       structures_destroyed >= 10 ~ \"10-99\",       TRUE ~ \"1-9 structures\"),     severity = factor(       severity,       levels = c(\"1-9 structures\", \"10-99\", \"100-999\", \"1,000+ structures\"))) |>   count(year, severity) |>   mutate(     .by = year,     percent = n / sum(n, na.rm = TRUE)) |>   ggplot(aes(x = year, y = percent, fill = severity)) +   geom_col() +   scale_fill_manual(values = c(     \"1-9 structures\" = palette_urbn_cyan[1],     \"10-99\" = palette_urbn_cyan[3],     \"100-999\" = palette_urbn_cyan[5],     \"1,000+ structures\" = palette_urbn_cyan[7])) +   scale_y_continuous(labels = scales::percent) +   labs(     title = \"Most wildifres destroy under 10 structures\",     x = \"\",     y = \"\")"},{"path":"https://ui-research.github.io/climateapi/articles/get_wildfire_burn_zones.html","id":"see-also","dir":"Articles","previous_headings":"","what":"See also","title":"Wildfire Burn Zones","text":"get_current_fire_perimeters(): Access current/active wildfire perimeters get_fema_disaster_declarations(): FEMA disaster declarations including fire-related declarations get_structures(): Estimate structures within geographic boundaries","code":""},{"path":"https://ui-research.github.io/climateapi/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Curran-Groome. Author, maintainer. Kameron Lloyd. Author.","code":""},{"path":"https://ui-research.github.io/climateapi/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Curran-Groome W, Lloyd K (2026). climateapi: Climate (adjacent) data functions C&C practice area. R package version 0.0.0.9001, https://ui-research.github.io/climateapi/.","code":"@Manual{,   title = {climateapi: Climate (and adjacent) data and functions for the C&C practice area},   author = {Will Curran-Groome and Kameron Lloyd},   year = {2026},   note = {R package version 0.0.0.9001},   url = {https://ui-research.github.io/climateapi/}, }"},{"path":"https://ui-research.github.io/climateapi/index.html","id":"climateapi","dir":"","previous_headings":"","what":"Climate (and adjacent) data and functions for the C&C practice area","title":"Climate (and adjacent) data and functions for the C&C practice area","text":"goal library(climateapi) minimize repeated data cleaning wrangling enable project teams devote time substantive analysis inference-making. package works toward goal creating unified interface common datasets data manipulation tasks. Functions () support climate-specific datasets well climate-adjacent.","code":""},{"path":"https://ui-research.github.io/climateapi/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Climate (and adjacent) data and functions for the C&C practice area","text":"can install development version climateapi GitHub :","code":"# install.packages(\"renv\") renv::install(\"UI-Research/climateapi\")"},{"path":"https://ui-research.github.io/climateapi/index.html","id":"the-climateapi-package-at-work","dir":"","previous_headings":"","what":"The climateapi package at work:","title":"Climate (and adjacent) data and functions for the C&C practice area","text":"","code":"library(climateapi) library(urbnindicators) library(sf) library(tidyverse) library(urbnthemes) set_urbn_defaults(style = \"print\")"},{"path":"https://ui-research.github.io/climateapi/index.html","id":"acs-housing-and-demographics","dir":"","previous_headings":"The climateapi package at work:","what":"ACS Housing and Demographics","title":"Climate (and adjacent) data and functions for the C&C practice area","text":"Capacity interacting data American Community Survey housed adjacent package, urbnindicators. Visit package’s webpage documentation learn .","code":""},{"path":"https://ui-research.github.io/climateapi/index.html","id":"major-disaster-declarations","dir":"","previous_headings":"The climateapi package at work:","what":"Major Disaster Declarations","title":"Climate (and adjacent) data and functions for the C&C practice area","text":"","code":"county_disaster_declarations = get_fema_disaster_declarations_county(api = TRUE)  county_disaster_declarations %>%   filter(stringr::str_detect(GEOID, \"^01\")) %>% ## Alabama   group_by(year_declared) %>%     summarize(annual_incidents = sum(incidents_all, na.rm = TRUE)) %>%   ggplot() +     geom_col(aes(x = year_declared, y = annual_incidents)) +     annotate(\"text\", x = 2016.5, y = 132, label = \"COVID-19 pandemic\" %>% str_wrap(10), fontface = \"bold\") +     labs(       title = \"COVID Results in a Spike of Counties with Disaster Declarations in 2020\",       subtitle = \"Sum of major disaster declarations per Alabama county, by year\",       x = \"\",       y = \"\") +     theme_urbn_print()"},{"path":"https://ui-research.github.io/climateapi/index.html","id":"wildfire-perimeters-and-structures","dir":"","previous_headings":"The climateapi package at work:","what":"Wildfire Perimeters and Structures","title":"Climate (and adjacent) data and functions for the C&C practice area","text":"","code":"## take the largest active fire wildfire_perimeters = get_current_fire_perimeters() %>%   dplyr::arrange(desc(incident_size_acres)) %>%   dplyr::slice(1) %>%   sf::st_transform(5070) %>%   sf::st_make_valid()  ## a two-item list ## the first item contains tract-level structure estimates ## the second contains the structure points impacted_structures = get_structures(   boundaries = wildfire_perimeters,   geography = \"tract\",   keep_structures = TRUE) #>   |                                                                              |                                                                      |   0%  |                                                                              |==                                                                    |   2%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  23%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |====================                                                  |  29%  |                                                                              |=======================                                               |  32%  |                                                                              |========================                                              |  34%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |===========================                                           |  38%  |                                                                              |==============================                                        |  44%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |==================================                                    |  48%  |                                                                              |===================================                                   |  50%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |=======================================                               |  55%  |                                                                              |==========================================                            |  61%  |                                                                              |============================================                          |  62%  |                                                                              |============================================                          |  63%  |                                                                              |=============================================                         |  64%  |                                                                              |===============================================                       |  67%  |                                                                              |================================================                      |  68%  |                                                                              |================================================                      |  69%  |                                                                              |=================================================                     |  70%  |                                                                              |==================================================                    |  71%  |                                                                              |==================================================                    |  72%  |                                                                              |===================================================                   |  72%  |                                                                              |=====================================================                 |  76%  |                                                                              |======================================================                |  77%  |                                                                              |======================================================                |  78%  |                                                                              |=======================================================               |  78%  |                                                                              |=======================================================               |  79%  |                                                                              |========================================================              |  79%  |                                                                              |========================================================              |  80%  |                                                                              |=========================================================             |  81%  |                                                                              |=========================================================             |  82%  |                                                                              |===========================================================           |  84%  |                                                                              |===========================================================           |  85%  |                                                                              |============================================================          |  85%  |                                                                              |============================================================          |  86%  |                                                                              |=============================================================         |  87%  |                                                                              |==============================================================        |  88%  |                                                                              |===============================================================       |  90%  |                                                                              |================================================================      |  91%  |                                                                              |=================================================================     |  92%  |                                                                              |=================================================================     |  93%  |                                                                              |==================================================================    |  94%  |                                                                              |==================================================================    |  95%  |                                                                              |===================================================================   |  95%  |                                                                              |====================================================================  |  96%  |                                                                              |======================================================================| 100% #> Reading layer `AZ_Structures' from data source  #>   `C:\\Users\\wcurrangroome\\Box\\METRO Climate and Communities Practice Area\\github-repository\\built-environment\\housing-units\\usa-structures\\raw\\AZ\\Deliverable20230502AZ\\AZ_Structures.gdb'  #>   using driver `OpenFileGDB' #> Simple feature collection with 2701791 features and 28 fields #> Geometry type: MULTIPOLYGON #> Dimension:     XY #> Bounding box:  xmin: -114.8118 ymin: 31.33255 xmax: -109.0454 ymax: 37.00252 #> Geodetic CRS:  WGS 84 #>   |                                                                              |                                                                      |   0%  |                                                                              |==                                                                    |   3%  |                                                                              |=====                                                                 |   7%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=================                                                     |  24%  |                                                                              |==================                                                    |  26%  |                                                                              |=====================                                                 |  30%  |                                                                              |=======================                                               |  33%  |                                                                              |========================                                              |  34%  |                                                                              |=========================                                             |  35%  |                                                                              |==========================                                            |  37%  |                                                                              |============================                                          |  41%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  46%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |=====================================                                 |  53%  |                                                                              |======================================                                |  54%  |                                                                              |===========================================                           |  61%  |                                                                              |==============================================                        |  65%  |                                                                              |================================================                      |  68%  |                                                                              |================================================                      |  69%  |                                                                              |=================================================                     |  71%  |                                                                              |====================================================                  |  75%  |                                                                              |=====================================================                 |  76%  |                                                                              |=======================================================               |  79%  |                                                                              |=========================================================             |  81%  |                                                                              |==========================================================            |  83%  |                                                                              |===========================================================           |  84%  |                                                                              |============================================================          |  86%  |                                                                              |==============================================================        |  88%  |                                                                              |===============================================================       |  90%  |                                                                              |================================================================      |  91%  |                                                                              |=================================================================     |  92%  |                                                                              |===================================================================   |  95%  |                                                                              |====================================================================  |  96%  |                                                                              |====================================================================  |  98%  |                                                                              |======================================================================| 100%  us_tracts_sf = tigris::tracts(cb = TRUE, year = 2023, progress_bar = FALSE) %>%   sf::st_transform(5070)  tracts_sf = us_tracts_sf %>%   sf::st_filter(wildfire_perimeters %>% st_transform(5070) %>% st_buffer(100000)) %>%   dplyr::select(GEOID) %>%   dplyr::left_join(     impacted_structures[[1]] %>%        dplyr::filter(occupancy_class == \"Residential\") %>%       dplyr::group_by(GEOID) %>%       dplyr::summarize(residential_units = sum(count, na.rm = TRUE)),      by = \"GEOID\") %>%   dplyr::mutate(county_fips = stringr::str_sub(GEOID, 1, 5)) %>%   dplyr::left_join(     tidycensus::fips_codes %>%        dplyr::mutate(county_fips = stringr::str_c(state_code, county_code)),      by = c(\"county_fips\"))  counties_sf = tracts_sf %>%   dplyr::group_by(county_fips, county) %>%    dplyr::summarize() %>%   dplyr::ungroup() %>%   dplyr::mutate(county = county %>% stringr::str_remove((\" County\")))  ggplot2::ggplot() +   geom_sf(data = tracts_sf, ggplot2::aes(fill = residential_units), linewidth = .6) +     ggplot2::scale_fill_continuous(na.value = \"darkgrey\") +   ggplot2::geom_sf(data = counties_sf, fill = NA, color = \"black\", linewidth = .75) +   ggplot2::geom_sf_text(data = counties_sf, color = \"black\", ggplot2::aes(label = county), fontface = \"bold\", size = 3) +   ggplot2::geom_sf(data = wildfire_perimeters, fill = NA, color = \"red\", linewidth = 1) +   ggplot2::labs(     title = \"Estimated Residential Units within Wildfire Boundaries, by Tract\",     subtitle = stringr::str_c(       \"Incident Name: \", wildfire_perimeters$incident_name, \" (\",        paste(         tracts_sf %>%            dplyr::filter(!is.na(residential_units)) %>%            dplyr::distinct(state_name) %>%           dplyr::pull(), collapse = \", \"), \") \\n\",       \"Incident Size: \", (round(wildfire_perimeters$incident_size_acres, 0) %>% scales::comma()), \" acres\", \"\\n\"),     fill = \"Residential units\") +   urbnthemes::theme_urbn_map()"},{"path":"https://ui-research.github.io/climateapi/index.html","id":"sba-disaster-loans","dir":"","previous_headings":"The climateapi package at work:","what":"SBA Disaster Loans","title":"Climate (and adjacent) data and functions for the C&C practice area","text":"","code":"sba_disaster_declarations = get_sba_loans()  sba_disaster_declarations %>%   dplyr::mutate(     fiscal_year = as.numeric(fiscal_year),     sba_approved = dplyr::if_else(approved_amount_total > 0, 1, 0)) %>%   ## some records, especially those from 2020 onwards, have NA values for approved fields   ## for that reason, we'll only look at years predating 2020   ## we're also going to exclude FY 2000--there are records for this year, but none   ## for the following three years, suggesting some... irregularities in the data   dplyr::filter(     !is.na(sba_approved),     fiscal_year > 2000,      fiscal_year < 2020) %>%   dplyr::group_by(loan_type, sba_approved, fiscal_year) %>%   dplyr::summarize(count = dplyr::n()) %>%   dplyr::ungroup() %>%   dplyr::mutate(     fill = dplyr::case_when(       loan_type == \"business\" & sba_approved == 1 ~ \"Business loans approved\",       loan_type == \"business\" & sba_approved == 0 ~ \"Business loans not approved\",       loan_type == \"residential\" & sba_approved == 1 ~ \"Residential loans approved\",       loan_type == \"residential\" & sba_approved == 0 ~ \"Residential loans not approved\")) %>%   ggplot2::ggplot() +   ggplot2::geom_col(ggplot2::aes(x = fiscal_year, y = count, fill = fill)) +   ggplot2::labs(     title = \"The Small Business Administration (SBA) Makes Many Residential Loans Post-Disaster\",     x = \"Fiscal year\",      y = \"Toal loan applications\") +   ggplot2::scale_fill_manual(     values = c(       \"Business loans approved\" = palette_urbn_cyan[5] %>% as.character,       \"Business loans not approved\" = palette_urbn_cyan[3] %>% as.character,       \"Residential loans approved\" = palette_urbn_yellow[5] %>% as.character,       \"Residential loans not approved\" = palette_urbn_yellow[3] %>% as.character)) +   ggplot2::scale_y_continuous(labels = scales::comma) +   ggplot2::scale_x_continuous(breaks = seq(2004, 2019, 3)) +   ggplot2::guides(fill = ggplot2::guide_legend(nrow = 2, byrow = TRUE))"},{"path":"https://ui-research.github.io/climateapi/index.html","id":"county-business-patterns","dir":"","previous_headings":"The climateapi package at work:","what":"County Business Patterns","title":"Climate (and adjacent) data and functions for the C&C practice area","text":"","code":"business_patterns = get_business_patterns()  business_patterns %>%   dplyr::filter(employee_size_range_code == \"001\") %>% ## all sizes   dplyr::group_by(state, county) %>%     dplyr::mutate(       industry_share_payroll = annual_payroll / annual_payroll[industry == \"total\"]) %>%     dplyr::filter(industry != \"total\") %>%   dplyr::ungroup() %>%   dplyr::filter(state == \"01\", county == \"001\") %>%   dplyr::mutate(industry = industry %>% janitor::make_clean_names(case = \"sentence\") %>% stringr::str_wrap(40)) %>%   ggplot2::ggplot() +     ggplot2::geom_col(ggplot2::aes(y = stats::reorder(industry, industry_share_payroll), x = industry_share_payroll)) +     ggplot2::labs(       x = \"Share of total payroll\",        y = \"Industry\",        title = \"Autauga County, AL's Industries (NAICS Codes) by Payroll Share\")"},{"path":"https://ui-research.github.io/climateapi/index.html","id":"government-expenses","dir":"","previous_headings":"The climateapi package at work:","what":"Government Expenses","title":"Climate (and adjacent) data and functions for the C&C practice area","text":"","code":"government_finances = get_government_finances()  government_finances %>%   dplyr::filter(state_code == \"01\", county_code == \"001\") %>%   dplyr::group_by(government_type) %>%     dplyr::summarize(       amount_millions = sum(amount_thousands, na.rm = TRUE) / 1000,       count = dplyr::n()) %>%   ggplot2::ggplot(aes(y = stats::reorder(government_type, amount_millions) %>% stringr::str_wrap(30), x = amount_millions)) +   ggplot2::geom_col() +   ggplot2::geom_text(ggplot2::aes(label = stringr::str_c(\"(N = \", count, \")\")), hjust = -.25) +   ggplot2::labs(x = \"Total annual expenditures (millions, USD)\",        y = \"\",        title = \"Autauga County, AL's Expenditures by Government Unit Class\",        subtitle = \"Government unit counts in parentheses\") +   ggplot2::scale_x_continuous(labels = scales::dollar, limits = c(0, 500)) +   ggplot2::theme(panel.grid.major = ggplot2::element_blank())"},{"path":"https://ui-research.github.io/climateapi/index.html","id":"lehd-origin-destination-employment-statistics-lodes","dir":"","previous_headings":"The climateapi package at work:","what":"LEHD Origin Destination Employment Statistics (LODES)","title":"Climate (and adjacent) data and functions for the C&C practice area","text":"","code":"lodes = get_lodes(     lodes_type = \"od\",     jobs_type = \"all\",     states = \"AL\",     years = 2022,     geography = \"tract\",     ## for simplicity, considering only workers who live and work in AL     state_part = \"main\") %>%   ## federal jobs are broken out separately in case users need to standardize   ## all-jobs counts over time, but this doesn't apply here   dplyr::filter(job_type == \"all\")  al_tracts = us_tracts_sf %>%   dplyr::filter(GEOID %>% str_sub(1,2) == \"01\") %>%   dplyr::select(GEOID) %>%   sf::st_transform(5070)  al_centroids = al_tracts %>%   sf::st_centroid() %>%   sf::st_transform(5070) %>%   sf::st_coordinates() %>%   tibble::as_tibble() %>%   cbind(al_tracts$GEOID) %>%   dplyr::rename(     x = X,     y = Y,     GEOID = 3)  major_al_cities = tidycensus::get_acs(     geography = \"place\",     variables = c(population = \"B01003_001\"),     year = 2022,     output = \"wide\",     state = \"AL\",     geometry = TRUE) %>%   dplyr::slice_max(populationE, n = 5) %>%   dplyr::transmute(     NAME = NAME %>%        stringr::str_remove_all(\"CDP|city|town|,|Alabama\") %>%        stringr::str_squish() %>%        stringr::str_trim()) #>   |                                                                              |                                                                      |   0%  |                                                                              |======                                                                |   9%  |                                                                              |====================                                                  |  28%  |                                                                              |=================================                                     |  47%  |                                                                              |===============================================                       |  67%  |                                                                              |============================================================          |  86%  |                                                                              |======================================================================| 100%  lodes %>%   dplyr::select(dplyr::matches(\"GEOID\"), total_jobs) %>%   dplyr::left_join(al_centroids, by = c(\"h_GEOID\" = \"GEOID\")) %>%   dplyr::left_join(al_centroids %>% dplyr::rename(xend = x, yend = y), by = c(\"w_GEOID\" = \"GEOID\")) %>%   filter(total_jobs > 20) %>%   ggplot() +     geom_sf(data = al_tracts, fill = \"lightgrey\", color = \"darkgrey\", linewidth = .5) +     geom_segment(       aes(x = x, y = y, xend = xend, yend = yend), color = palette_urbn_main[1], alpha = .1) +     geom_sf(data = major_al_cities, fill = NA, color = \"black\") +     geom_sf_text(data = major_al_cities, aes(label = NAME), size = 3, , fontface = \"bold\", color = \"black\", vjust = -2) +     theme_urbn_map() +   labs(title = \"Employment Commuting Patterns by Tract in Alabama (2022)\")"},{"path":"https://ui-research.github.io/climateapi/reference/cache_it.html","id":null,"dir":"Reference","previous_headings":"","what":"Cache an object to a parquet file; optionally read from disk — cache_it","title":"Cache an object to a parquet file; optionally read from disk — cache_it","text":"function writes R object parquet file automatic datestamp (YYYY_MM_DD format) filename. can also read existing cached file one exists. sf objects, function automatically uses sfarrow reading/writing adds \"_sf\" filename indicate file format.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/cache_it.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cache an object to a parquet file; optionally read from disk — cache_it","text":"","code":"cache_it(object, file_name = NULL, path = \".\", read = TRUE, keep_n = 5)"},{"path":"https://ui-research.github.io/climateapi/reference/cache_it.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cache an object to a parquet file; optionally read from disk — cache_it","text":"object dataframe, tibble, sf object cache. Can provided either quoted unquoted name. Optional reading cache - case, file_name must provided. file_name File name (without extension). Optional object provided (uses object's name). Required object missing reading cache. Must contain path separators invalid filename characters. path Directory path file saved/read. Defaults current directory (\".\"). path exist, user prompted create (interactive sessions) error thrown (non-interactive sessions). read Logical character. TRUE default. TRUE: Find read recent cached version based datestamp. FALSE: Skip reading, always write new cached file Character: Read specific file exact filename (including extension). Defaults TRUE. keep_n Integer. Maximum number cached versions keep. writing new file, older versions beyond limit deleted. Defaults 5. Set NULL Inf keep versions.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/cache_it.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cache an object to a parquet file; optionally read from disk — cache_it","text":"object cached (either written read)","code":""},{"path":"https://ui-research.github.io/climateapi/reference/cache_it.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cache an object to a parquet file; optionally read from disk — cache_it","text":"","code":"if (FALSE) { # \\dontrun{ ## Note: datestamps in filenames are illustrative; user results will ## vary depending on the date at runtime  # Regular data frames my_data <- tibble(x = 1:10, y = letters[1:10])  # Cache with automatic naming and datestamp (writes to current directory) cache_it(my_data)  # Creates: ./my_data_2025_12_07.parquet  # Cache with custom filename and path cache_it(my_data, file_name = \"custom_name\", path = \"data\")  # Read most recent cached version if exists, otherwise write cached_data <- cache_it(my_data, read = TRUE)  # Always write a new file, don't read from cache cache_it(my_data, read = FALSE)  # Read a specific cached file by name old_data <- cache_it(my_data, read = \"my_data_2025_12_01.parquet\")  # Read from cache when object doesn't exist in environment yet (using file_name) my_data <- cache_it(file_name = \"my_data\", read = TRUE)  # Read from cache when object doesn't exist (using quoted name) my_data <- cache_it(\"my_data\", read = TRUE)  # Read from cache when object doesn't exist (using unquoted name) my_data <- cache_it(my_data, read = TRUE)  # Read specific file when object doesn't exist old_data <- cache_it(read = \"my_data_2025_12_01.parquet\")  # Keep only the 3 most recent cached versions cache_it(my_data, keep_n = 3)  # Keep all cached versions (no cleanup) cache_it(my_data, keep_n = NULL)  # SF objects (automatically uses sfarrow) my_sf <- sf::st_read(system.file(\"shape/nc.shp\", package=\"sf\")) cache_it(my_sf)  # Creates: ./my_sf_2025_12_07_sf.parquet  # Read most recent sf cached file cached_sf <- cache_it(my_sf, read = TRUE)  # Read specific sf cached file old_sf <- cache_it(my_sf, read = \"my_sf_2025_12_01_sf.parquet\") } # }"},{"path":"https://ui-research.github.io/climateapi/reference/convert_delimited_to_parquet.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert raw data to parquet to conserve memory / speed subsequent operations — convert_delimited_to_parquet","title":"Convert raw data to parquet to conserve memory / speed subsequent operations — convert_delimited_to_parquet","text":"Convert raw data parquet conserve memory / speed subsequent operations","code":""},{"path":"https://ui-research.github.io/climateapi/reference/convert_delimited_to_parquet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert raw data to parquet to conserve memory / speed subsequent operations — convert_delimited_to_parquet","text":"","code":"convert_delimited_to_parquet(   inpath,   outpath = NULL,   delimit_character = \",\",   subsetted_columns = NULL,   dataset = NULL )"},{"path":"https://ui-research.github.io/climateapi/reference/convert_delimited_to_parquet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert raw data to parquet to conserve memory / speed subsequent operations — convert_delimited_to_parquet","text":"inpath local path read CSV data . outpath local path write parquet data . delimit_character delimiting character raw data. subsetted_columns columns include outputted parquet data. dataset NULL default. Alternately, one c(\"nfip_policies\", \"ihp_registrations\"). null, used select columns returned.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/convert_delimited_to_parquet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert raw data to parquet to conserve memory / speed subsequent operations — convert_delimited_to_parquet","text":"NULL (invisibly). function called side effect writing parquet file disk specified outpath (path derived inpath .parquet extension). function reads input file chunks handle large files efficiently, optionally subsets specified columns, writes result Apache Parquet format using arrow::write_parquet().","code":""},{"path":"https://ui-research.github.io/climateapi/reference/convert_table_text_to_dataframe.html","id":null,"dir":"Reference","previous_headings":"","what":"Use an LLM to Convert Table Text to a Dataframe — convert_table_text_to_dataframe","title":"Use an LLM to Convert Table Text to a Dataframe — convert_table_text_to_dataframe","text":"common encounter valuable tabular data stored file type codify tabular data , e.g., table PDF .docx file. function uses user-specified LLM (OpenAI Anthropic) convert text table dataframe. Note users must API key credits specified LLM. typical full-page PDF table, LLM costs roughly $.02-.05 USD per page.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/convert_table_text_to_dataframe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use an LLM to Convert Table Text to a Dataframe — convert_table_text_to_dataframe","text":"","code":"convert_table_text_to_dataframe(   text,   column_types,   llm_company_name = \"openai\",   preprocess = TRUE,   read_warning = FALSE,   short_document = FALSE,   required = FALSE )"},{"path":"https://ui-research.github.io/climateapi/reference/convert_table_text_to_dataframe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use an LLM to Convert Table Text to a Dataframe — convert_table_text_to_dataframe","text":"text table--text input. page input vector list item, default using pdftools::pdf_text(). Non-table text input text minimized. column_types column types output dataframe. type_object object ellmer package. Including descriptions column represents improves accuracy. llm_company_name One c(\"openai\", \"anthropic\"). Default \"openai\". preprocess text preprocessed passed LLM? Default TRUE. removes unneeded spaces, line breaks, page numbers. read_warning user read function documentation? short_document Boolean; default FALSE. TRUE, assumed document short enough can processed single API call. FALSE inputted text single item, function throws error. Note multi-page documents broken multi-item vectors/lists passed text. required Boolean; default FALSE. TRUE, LLM instructed return values columns. FALSE, NULL values allowed. Generally, NULL values allowed unless certain every value inputted text-table non-NULL value.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/convert_table_text_to_dataframe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Use an LLM to Convert Table Text to a Dataframe — convert_table_text_to_dataframe","text":"list tibbles, list element corresponds one item (typically one page) input text vector/list. tibble contains: Structure Columns match names types defined column_types. row represents one record extracted table text LLM. NULL values required = FALSE (default), columns may contain NULL/NA values LLM extract value cell. Empty dataframes LLM encounters error processing page, list element empty data.frame(). Use purrr::list_rbind() dplyr::bind_rows() consolidate results single dataframe. warning issued reminding users review AI-generated results accuracy.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/convert_table_text_to_dataframe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Use an LLM to Convert Table Text to a Dataframe — convert_table_text_to_dataframe","text":"","code":"if (FALSE) { # \\dontrun{ column_types = type_object(  col1 = type_string(\"Zip code\"),  col2 = type_integer(\"Number of buildings\"))  convert_table_text_to_dataframe(  text = example_text,  column_types = column_types,  preprocess = TRUE,  read_warning = TRUE,  llm_company_name = \"openai\",  short_document = TRUE,  required = FALSE) } # }"},{"path":"https://ui-research.github.io/climateapi/reference/estimate_units_per_parcel.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the number and types of structures per parcel — estimate_units_per_parcel","title":"Estimate the number and types of structures per parcel — estimate_units_per_parcel","text":"Estimate number types structures per parcel","code":""},{"path":"https://ui-research.github.io/climateapi/reference/estimate_units_per_parcel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the number and types of structures per parcel — estimate_units_per_parcel","text":"","code":"estimate_units_per_parcel(structures, parcels, zoning, acs = NULL)"},{"path":"https://ui-research.github.io/climateapi/reference/estimate_units_per_parcel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the number and types of structures per parcel — estimate_units_per_parcel","text":"structures dataset returned get_structure(). parcels spatial (polygon) dataset. zoning spatial (polygon) zoning dataset. acs Optionally, non-spatial dataset, tract level, returned urbnindicators::compile_acs_data().","code":""},{"path":"https://ui-research.github.io/climateapi/reference/estimate_units_per_parcel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the number and types of structures per parcel — estimate_units_per_parcel","text":"sf object (point geometry, representing parcel centroids) containing input parcel data augmented estimated residential unit information. returned object includes: parcel_id Character numeric. unique parcel identifier input data. tract_geoid Character. 11-digit Census tract GEOID containing parcel centroid. jurisdiction Character. jurisdiction name associated parcel. municipality_name Character. municipality name associated parcel. residential_unit_count Numeric. estimated number residential units parcel, benchmarked ACS estimates tract level. residential_unit_categories Factor (ordered). Categorical classification unit counts: \"0\", \"1\", \"2\", \"3-4\", \"5-9\", \"10-19\", \"20-49\", \"50+\". median_value_improvement_sf Numeric. Tract-level median improvement value single-family parcels. median_value_improvement_mh Numeric. Tract-level median improvement value manufactured home parcels. acs_units_N Numeric columns (acs_units_1, acs_units_2, etc.). ACS-reported housing unit counts units--structure category tract. zone Character. Zoning designation zoning dataset. zoned_housing_type Character. Housing type allowed zoning. far Numeric. Floor area ratio. setback_front Numeric. Front setback requirement feet. setback_rear Numeric. Rear setback requirement feet. setback_side Numeric. Side setback requirement feet. height_maximum Numeric. Maximum building height allowed.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/estimate_zoning_envelope.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the number of units allowed on a parcel — estimate_zoning_envelope","title":"Calculate the number of units allowed on a parcel — estimate_zoning_envelope","text":"Calculate number units allowed parcel","code":""},{"path":"https://ui-research.github.io/climateapi/reference/estimate_zoning_envelope.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the number of units allowed on a parcel — estimate_zoning_envelope","text":"","code":"estimate_zoning_envelope(   parcels,   development_size_maximum = 300,   standard_unit_sqft_multifamily = 1000,   standard_parking_stall_sqft = 325,   parking_model = \"singlestory\" )"},{"path":"https://ui-research.github.io/climateapi/reference/estimate_zoning_envelope.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the number of units allowed on a parcel — estimate_zoning_envelope","text":"parcels dataframe containing parcel-level attributes zoning regulations development_size_maximum cap number units can developed parcel. Note larger values increase length computation. standard_unit_sqft_multifamily square footage standard multifamily unit standard_parking_stall_sqft square footage standard parking space parking_model One c(\"singlestory\", \"multistory\"). model parking requirements: stalls ground floor distributed vertically?","code":""},{"path":"https://ui-research.github.io/climateapi/reference/estimate_zoning_envelope.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the number of units allowed on a parcel — estimate_zoning_envelope","text":"input parcels dataframe additional column, maximum_development_capacity_zoned, contains maximum number units can developed parcel per zoning regulations","code":""},{"path":"https://ui-research.github.io/climateapi/reference/estimate_zoning_envelope.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the number of units allowed on a parcel — estimate_zoning_envelope","text":"","code":"df = tibble::tibble(  parcel_id = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10),  parcel_area_sqft = c(1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000),  setback_front = c(10),  setback_rear = c(10),  setback_side = c(10),  parcel_area_sqft_minimum = c(1000, 1000, 1000, 1000, 1000, 5000, 5000, 5000, 5000, 5000),  units_per_parcel_maximum = c(10),  units_per_acre_maximum = NA,  parcel_coverage_percent_maximum = c(70),  parcel_coverage_percent_maximum_building = c(70),  open_space_ratio_minimum = c(0.2),  floor_area_ratio_maximum = c(1, 1, 2, 2, 3, 3, 4, 4, 5, 5),  height_stories_maximum = c(3, 3, 3, 3, 3, 5, 5, 5, 5, 5),  height_feet_maximum = NA,  parking_stalls_per_parcel_minimum = c(1),  parking_stalls_per_unit_minimum = c(2, 2, 2, 2, 2, 1, 1, 1, 1, 1))   estimate_zoning_envelope(    parcels = df) #> # A tibble: 10 × 30 #>    parcel_id parcel_area_sqft setback_front setback_rear setback_side #>        <dbl>            <dbl>         <dbl>        <dbl>        <dbl> #>  1         1             1000            10           10           10 #>  2         2             2000            10           10           10 #>  3         3             3000            10           10           10 #>  4         4             4000            10           10           10 #>  5         5             5000            10           10           10 #>  6         6             6000            10           10           10 #>  7         7             7000            10           10           10 #>  8         8             8000            10           10           10 #>  9         9             9000            10           10           10 #> 10        10            10000            10           10           10 #> # ℹ 25 more variables: parcel_area_sqft_minimum <dbl>, #> #   units_per_parcel_maximum <dbl>, units_per_acre_maximum <lgl>, #> #   parcel_coverage_percent_maximum <dbl>, #> #   parcel_coverage_percent_maximum_building <dbl>, #> #   open_space_ratio_minimum <dbl>, floor_area_ratio_maximum <dbl>, #> #   height_stories_maximum <dbl>, height_feet_maximum <lgl>, #> #   parking_stalls_per_parcel_minimum <dbl>, …"},{"path":"https://ui-research.github.io/climateapi/reference/get_box_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the path to the C&C Box folder — get_box_path","title":"Get the path to the C&C Box folder — get_box_path","text":"Get path C&C Box folder","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_box_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the path to the C&C Box folder — get_box_path","text":"","code":"get_box_path()"},{"path":"https://ui-research.github.io/climateapi/reference/get_box_path.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the path to the C&C Box folder — get_box_path","text":"character string containing full file path Climate Communities (C&C) Box folder. Windows, returns \"C:/Users/username/Box/METRO Climate Communities Practice Area/github-repository\". Mac, checks Box \"/Users/username/Box\" \"/Users/username/Library/CloudStorage/Box-Box\", using whichever exists. Throws error Box folder found.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_box_path.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the path to the C&C Box folder — get_box_path","text":"","code":"if (FALSE) { # \\dontrun{ get_box_path() } # }"},{"path":"https://ui-research.github.io/climateapi/reference/get_business_patterns.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain County Business Patterns (CBP) Estimates per County — get_business_patterns","title":"Obtain County Business Patterns (CBP) Estimates per County — get_business_patterns","text":"Obtain County Business Patterns (CBP) Estimates per County","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_business_patterns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain County Business Patterns (CBP) Estimates per County — get_business_patterns","text":"","code":"get_business_patterns(   year = 2023,   geo = \"county\",   naics_code_digits = 2,   naics_codes = NULL )"},{"path":"https://ui-research.github.io/climateapi/reference/get_business_patterns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain County Business Patterns (CBP) Estimates per County — get_business_patterns","text":"year vintage CBP data desired. Data available 2008-2023. Earlier years use different NAICS classification systems currently supported. Default 2023. geo level geography CBP data desired. Either \"county\" \"zipcode\". Zipcode level data ZIP Code Business Patterns (ZBP) dataset includes number establishments, employment week March 12th, first quarter annual payroll NAICS 00 (total sectors). Additionally, number establishments (employment payroll) available employment size establishment 2- 6-digit NAICS. naics_code_digits One c(2, 3). Default 2. NAICS codes range specificity; 2-digit codes describe highest groupings industries, six-digit codes exceedingly detailed. 20 2-digit NAICS codes 196 3-digit codes. specific codes desired, leave argument NULL supply desired codes argument naics_codes. naics_codes vector NAICS codes query. NULL, function query available codes specified number digits. NULL, argument overrides naics_code_digits argument.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_business_patterns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain County Business Patterns (CBP) Estimates per County — get_business_patterns","text":"tibble data county-level employees, employers, aggregate annual payrolls industry employer size year year CBP data pulled state two-digit state identifier. county three-digit county identifier. employees number individual employees employed particular industry establishment size combination employers number establishments employment size annual_payroll total annual payroll expenditures measured $1,000's USD industry industry classification according North American Industry Classification System. Refer details additional information employee_size_range_label range employment size establishments included given grouping employee_size_range_code three-digit code used categorize employment sizes naics_code two six-digit code used NAICS categorize sub-categorize industries","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_business_patterns.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Obtain County Business Patterns (CBP) Estimates per County — get_business_patterns","text":"County Business Patterns (CBP) annual series provides subnational economic data establishments paid employees industry employment size. series includes number establishments, employment week March 12, first quarter payroll, annual payroll. Industry classification business establishments CBP according North American Industry Classification System (NAICS) https://www.census.gov/naics/ CBP data useful studying economic activity small areas. Federal agencies use data determine employee concentrations trends industry. State local government offices use data assess business changes, develop fiscal policies, plan future policies programs. CBP data used benchmark public private sector statistical series, surveys, databases economic census years. similar LEHD Origin-Destination Employment Statistics (LODES) data coverage employment statistics, CBP differs mainly due broader geographies (county vs. tract) focus framing statistics establishment/company level rather individual/job level found LODES data. CBP also offer information locations jobs relation employee actually resides. series excludes data self-employed individuals, employees private households, railroad employees, agricultural production employees, government employees. certain amount undercoverage occurs universe, Census Bureau create multi-unit company structure Business Register small employers (less 10 employees) identified Economic Census. CBP covers NAICS industries excluding Crop Animal Production (NAICS 111,112); Rail Transportation (NAICS 482); Postal Service (NAICS 491); Pension, Health, Welfare, Insurance Funds (NAICS 525110, 525120, 525190); Trusts, Estates, Agency Accounts (NAICS 525920); Offices Notaries (NAICS 541120); Private Households (NAICS 814); Public Administration (NAICS 92)","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_business_patterns.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain County Business Patterns (CBP) Estimates per County — get_business_patterns","text":"","code":"if (FALSE) { # \\dontrun{ get_business_patterns(  year = 2023,  naics_code_digits = 3)  get_business_patterns(  year = 2017,  naics_codes = c(221111, 221112)) } # }"},{"path":"https://ui-research.github.io/climateapi/reference/get_current_fire_perimeters.html","id":null,"dir":"Reference","previous_headings":"","what":"Acquire current wildfire perimeters — get_current_fire_perimeters","title":"Acquire current wildfire perimeters — get_current_fire_perimeters","text":"Retrieves current wildfire perimeter data NIFC (National Interagency Fire Center) via Wildland Fire Interagency Geospatial Services (WFIGS) API.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_current_fire_perimeters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Acquire current wildfire perimeters — get_current_fire_perimeters","text":"","code":"get_current_fire_perimeters(   geography = NULL,   file_path = NULL,   bbox = NULL,   api = TRUE )"},{"path":"https://ui-research.github.io/climateapi/reference/get_current_fire_perimeters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Acquire current wildfire perimeters — get_current_fire_perimeters","text":"geography Included API consistency; must NULL. file_path Included API consistency; must NULL. bbox Optionally, sf::st_bbox() object, object can converted . api Included API consistency; must TRUE.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_current_fire_perimeters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Acquire current wildfire perimeters — get_current_fire_perimeters","text":"sf dataframe comprising perimeters current wildfires. Columns include: unique_id Unique identifier observation (generated). incident_name Name fire incident (title case). incident_size_acres Size fire acres. incident_short_description Brief description incident. percent_contained Percent fire contained (0-100). identified_date Date/time fire discovered. updated_date Date/time record last updated. geometry Polygon geometry fire perimeter.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_current_fire_perimeters.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Acquire current wildfire perimeters — get_current_fire_perimeters","text":"Data NIFC WFIGS service. See https://data-nifc.opendata.arcgis.com/datasets/nifc::wfigs-interagency-fire-perimeters/.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_current_fire_perimeters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Acquire current wildfire perimeters — get_current_fire_perimeters","text":"","code":"if (FALSE) { # \\dontrun{ get_current_fire_perimeters() } # }"},{"path":"https://ui-research.github.io/climateapi/reference/get_dataset_columns.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the raw column names for a specified dataset — get_dataset_columns","title":"Get the raw column names for a specified dataset — get_dataset_columns","text":"Get raw column names specified dataset","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_dataset_columns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the raw column names for a specified dataset — get_dataset_columns","text":"","code":"get_dataset_columns(dataset)"},{"path":"https://ui-research.github.io/climateapi/reference/get_dataset_columns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the raw column names for a specified dataset — get_dataset_columns","text":"dataset name dataset. One c('nfip_policies', 'ihp_registrations').","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_dataset_columns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the raw column names for a specified dataset — get_dataset_columns","text":"character vector containing raw column names (camelCase format appear source data) selected reading specified dataset. columns returned curated subsets full dataset columns, excluding administrative/metadata fields. \"nfip_policies\": 20 columns including location, policy details, building characteristics. \"ihp_registrations\": ~20 columns including disaster info, geographic identifiers, assistance amounts.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_disaster_dollar_database.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Disaster Dollar Database Data — get_disaster_dollar_database","title":"Get Disaster Dollar Database Data — get_disaster_dollar_database","text":"Get Disaster Dollar Database Data","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_disaster_dollar_database.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Disaster Dollar Database Data — get_disaster_dollar_database","text":"","code":"get_disaster_dollar_database(   file_path = file.path(get_box_path(), \"hazards\", \"carnegie-endowment\",     \"disaster_dollar_database_2025_11_19.csv\") )"},{"path":"https://ui-research.github.io/climateapi/reference/get_disaster_dollar_database.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Disaster Dollar Database Data — get_disaster_dollar_database","text":"file_path path (Box) file containing raw data.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_disaster_dollar_database.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Disaster Dollar Database Data — get_disaster_dollar_database","text":"dataframe comprising disaster-level observations financial assistance metrics FEMA's Individual Households Program (IHP), Public Assistance (PA), HUD's Community Development Block Grant Disaster Recovery (CDBG-DR), SBA disaster loans.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_disaster_dollar_database.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Disaster Dollar Database Data — get_disaster_dollar_database","text":"data sourced : https://carnegieendowment.org/features/disaster-dollar-database. data returned function unchanged, though columns renamed slightly clarity consistency.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_disaster_dollar_database.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Disaster Dollar Database Data — get_disaster_dollar_database","text":"","code":"if (FALSE) { # \\dontrun{ get_disaster_dollar_database() } # }"},{"path":"https://ui-research.github.io/climateapi/reference/get_emergency_management_performance.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Emergency Management Performance Grant (EMPG) data — get_emergency_management_performance","title":"Get Emergency Management Performance Grant (EMPG) data — get_emergency_management_performance","text":"Retrieves Emergency Management Performance Grant (EMPG) award data FEMA, supports state local emergency management agencies.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_emergency_management_performance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Emergency Management Performance Grant (EMPG) data — get_emergency_management_performance","text":"","code":"get_emergency_management_performance(   file_path = file.path(get_box_path(), \"hazards\", \"FEMA\",     \"emergency-management-performance\",     \"emergency_management_performance_grants_2025_06_29.csv\"),   api = TRUE )"},{"path":"https://ui-research.github.io/climateapi/reference/get_emergency_management_performance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Emergency Management Performance Grant (EMPG) data — get_emergency_management_performance","text":"file_path Path downloaded dataset Box. api Logical indicating whether use OpenFEMA API retrieve data. Default TRUE.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_emergency_management_performance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Emergency Management Performance Grant (EMPG) data — get_emergency_management_performance","text":"data frame containing emergency management performance grant (EMPG) data. Columns include: id Unique identifier grant record. state_name Full state name. state_code Two-digit state FIPS code. state_abbreviation Two-letter state abbreviation. year_project_start Year project started. project_start_date Date project started. project_end_date Date project ended. grant_amount Total grant amount dollars. federal_share Federal portion grant dollars. non_federal_share Non-federal cost share dollars. program EMPG program type.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_emergency_management_performance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Emergency Management Performance Grant (EMPG) data — get_emergency_management_performance","text":"Data FEMA's OpenFEMA API. See https://www.fema.gov/openfema-data-page/emergency-management-performance-grants-v2.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_fema_disaster_declarations.html","id":null,"dir":"Reference","previous_headings":"","what":"Get major disaster declarations by county — get_fema_disaster_declarations","title":"Get major disaster declarations by county — get_fema_disaster_declarations","text":"Retrieves FEMA Major Disaster Declarations county level, aggregated year month. Tribal declarations stored separately attribute.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_fema_disaster_declarations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get major disaster declarations by county — get_fema_disaster_declarations","text":"","code":"get_fema_disaster_declarations(   file_path = file.path(get_box_path(), \"hazards\", \"fema\", \"disaster-declarations\",     \"raw\", \"fema_disaster_declarations_county_2024_10_25.csv\"),   api = TRUE )"},{"path":"https://ui-research.github.io/climateapi/reference/get_fema_disaster_declarations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get major disaster declarations by county — get_fema_disaster_declarations","text":"file_path path (Box) file containing raw data. api TRUE (default), access data API. Else, read locally file_path.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_fema_disaster_declarations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get major disaster declarations by county — get_fema_disaster_declarations","text":"dataframe comprising Major Disaster Declarations month year county. Tribal declarations stored attribute (tribal_declarations). Columns include: unique_id Unique identifier observation. GEOID Five-digit county FIPS code. year_declared Year disaster declared. month_declared Month disaster declared (1-12). declaration_title Title(s) disaster declaration(s). incidents_all Total count disaster declarations county-month. incidents_natural_hazard Count natural hazard declarations. incidents_* Additional columns incident types, reflects count given incident type.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_fema_disaster_declarations.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get major disaster declarations by county — get_fema_disaster_declarations","text":"Data FEMA's OpenFEMA API. See https://www.fema.gov/openfema-data-page/disaster-declarations-summaries-v2. Statewide declarations expanded counties state.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_fema_disaster_declarations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get major disaster declarations by county — get_fema_disaster_declarations","text":"","code":"if (FALSE) { # \\dontrun{ get_fema_disaster_declarations(api = TRUE) } # }"},{"path":"https://ui-research.github.io/climateapi/reference/get_geography_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Get geography metadata about states or counties — get_geography_metadata","title":"Get geography metadata about states or counties — get_geography_metadata","text":"Get geography metadata states counties","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_geography_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get geography metadata about states or counties — get_geography_metadata","text":"","code":"get_geography_metadata(geography_type = c(\"state\", \"county\"), year = 2023)"},{"path":"https://ui-research.github.io/climateapi/reference/get_geography_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get geography metadata about states or counties — get_geography_metadata","text":"geography_type One c(\"state\", \"county\"). year year obtain state/county metadata. greater recent year supported library(tidycensus) 5-year ACS.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_geography_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get geography metadata about states or counties — get_geography_metadata","text":"tibble containing geographic metadata. structure varies geography_type: \"county\" Returns county-level data columns: state_code (2-digit FIPS), state_name, state_abbreviation (2-letter USPS), state_population, county_code (5-digit FIPS), county_name, county_population. \"state\" Returns state-level data columns: state_abbreviation, state_code, state_name (one row per state, county information). Population data sourced ACS 5-year estimates specified year.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_government_finances.html","id":null,"dir":"Reference","previous_headings":"","what":"Get county government revenues and expenditures — get_government_finances","title":"Get county government revenues and expenditures — get_government_finances","text":"Retrieves county government revenues expenditures time.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_government_finances.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get county government revenues and expenditures — get_government_finances","text":"","code":"get_government_finances()"},{"path":"https://ui-research.github.io/climateapi/reference/get_government_finances.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get county government revenues and expenditures — get_government_finances","text":"dataframe containing county government-level revenues expenditures year. monetary values thousands dollars. year Year financial data. GEOID Five-digit county FIPS code. county_name Name county. revenue_total Total county revenue. revenue_general General revenue (excludes utilities, liquor stores, social insurance). revenue_tax_total Total tax revenue. revenue_tax_property Property tax revenue. revenue_tax_sales Sales gross receipts tax revenue. revenue_tax_income Income tax revenue. revenue_intergovernmental_total Total intergovernmental transfers received. revenue_intergovernmental_federal Federal intergovernmental transfers. revenue_intergovernmental_state State intergovernmental transfers. revenue_charges_total Total charges miscellaneous general revenue. revenue_utility_total Utility revenue. expenditure_total Total county expenditures. expenditure_general General expenditures. expenditure_capital_outlay Capital outlay spending. expenditure_construction Construction spending. expenditure_salaries_wages Salaries wages. expenditure_intergovernmental Intergovernmental transfers paid. expenditure_education_total Education spending. expenditure_public_safety Police protection spending. expenditure_health_hospitals Health spending. expenditure_highways Highway spending. expenditure_public_welfare Public welfare spending. expenditure_utility_total Utility expenditures.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_government_finances.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get county government revenues and expenditures — get_government_finances","text":"Data U.S. Census Bureau's Annual Survey State Local Government Finances Census Governments, compiled per: Pierson K., Hand M., Thompson F. (2015). Government Finance Database: Common Resource Quantitative Research Public Financial Analysis. PLoS ONE doi: 10.1371/journal.pone.0130119. See https://.willamette.edu/site/mba/public-datasets. survey years–.e., subset full population governments comprises sampling frame–true census relatively high response rates (90%%+) years ending 2 7. Definitions key constructs: Revenues General revenue: revenue arising utilities, liquor stores, social insurance. Intergovernmental revenue: Transfers federal, state, local governments. Current charges: Fees collected providing services. Expenditures General expenditure: spending except utilities, liquor stores, social insurance. Capital outlay: Spending construction equipment.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_hazard_mitigation_assistance.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Hazard Mitigation Assistance (HMA) Project Details — get_hazard_mitigation_assistance","title":"Get Hazard Mitigation Assistance (HMA) Project Details — get_hazard_mitigation_assistance","text":"Retrieves Hazard Mitigation Assistance project data legacy HMA Projects dataset newer FEMA GO subapplications dataset, harmonized project-county level.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_hazard_mitigation_assistance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Hazard Mitigation Assistance (HMA) Project Details — get_hazard_mitigation_assistance","text":"","code":"get_hazard_mitigation_assistance(   file_path_old_grant_system = file.path(get_box_path(), \"hazards\", \"fema\",     \"hazard-mitigation-assistance\", \"raw\",     \"HazardMitigationAssistanceProjects_2025_09_27.parquet\"),   file_path_new_grant_system = file.path(get_box_path(), \"hazards\", \"fema\",     \"hazard-mitigation-assistance\", \"raw\", \"HmaSubapplications_2025_09_27.parquet\"),   state_abbreviations = NULL )"},{"path":"https://ui-research.github.io/climateapi/reference/get_hazard_mitigation_assistance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Hazard Mitigation Assistance (HMA) Project Details — get_hazard_mitigation_assistance","text":"file_path_old_grant_system file path raw data HMA applications older grant-reporting system. data typically available : https://www.fema.gov/openfema-data-page/hazard-mitigation-assistance-projects-v4 file_path_new_grant_system file path raw data HMA applications newer (FEMA GO) grant-reporting system. data typically available : https://www.fema.gov/openfema-data-page/hma-subapplications-v2 state_abbreviations NULL default, case data returned 51 states. Provide vector two-character USPS state abbreviations obtain data sub-selection states.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_hazard_mitigation_assistance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Hazard Mitigation Assistance (HMA) Project Details — get_hazard_mitigation_assistance","text":"dataframe project-county HMA application data. project_cost_federal_split used county-level aggregations. Columns include: data_source \"hma-projects\" (legacy) \"hma-subapplications\" (FEMA GO). project_id Unique project identifier. disaster_number FEMA disaster number (disaster-related). project_program_area HMA program: HMGP, BRIC, FMA, PDM. project_fiscal_year Fiscal year project. state_name Full state name. county_geoid Five-digit county FIPS code. county_population County population used allocation. project_status Current project status (e.g., \"Closed\", \"Active\"). project_cost_federal Total federal cost project level. project_cost_federal_split Federal cost allocated county.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_hazard_mitigation_assistance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Hazard Mitigation Assistance (HMA) Project Details — get_hazard_mitigation_assistance","text":"Data FEMA's OpenFEMA API, combining two data sources: legacy Hazard Mitigation Assistance Projects (v4) newer HMA Subapplications (v2). Multi-county projects split across counties based population proportions.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_hazard_mitigation_assistance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Hazard Mitigation Assistance (HMA) Project Details — get_hazard_mitigation_assistance","text":"","code":"if (FALSE) { # \\dontrun{ get_hazard_mitigation_assistance() } # }"},{"path":"https://ui-research.github.io/climateapi/reference/get_ihp_registrations.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Individuals and Households Program (IHP) registrations — get_ihp_registrations","title":"Get Individuals and Households Program (IHP) registrations — get_ihp_registrations","text":"Retrieves FEMA Individual Households Program (IHP) registration data, captures applications disaster assistance individuals households.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_ihp_registrations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Individuals and Households Program (IHP) registrations — get_ihp_registrations","text":"","code":"get_ihp_registrations(   state_fips = NULL,   file_name = \"IndividualsAndHouseholdsProgramValidRegistrationsV2_2025_09_26.parquet\",   api = FALSE,   outpath = NULL )"},{"path":"https://ui-research.github.io/climateapi/reference/get_ihp_registrations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Individuals and Households Program (IHP) registrations — get_ihp_registrations","text":"state_fips character vector two-letter state abbreviations. NULL (default), return data 51 states. Otherwise return data specified states. file_name name (full path) Box file containing raw data. api TRUE, query API. FALSE (default), read disk. outpath path save parquet-formatted datafile. Applicable api = FALSE.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_ihp_registrations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Individuals and Households Program (IHP) registrations — get_ihp_registrations","text":"dataframe comprising IHP registrations. Note records duplicated due many--many join ZCTA--county crosswalk; use allocation_factor_zcta_to_county properly aggregate. Columns include: unique_id Unique identifier original registration. allocation_factor_zcta_to_county Weight attributing registration county. geoid_county Five-digit county FIPS code. zcta_code Five-digit ZIP Code Tabulation Area. geoid_tract 11-digit census tract FIPS code. geoid_block_group 12-digit census block group FIPS code. disaster_number FEMA disaster number. amount_individual_housing_program Total IHP assistance amount dollars. amount_housing_assistance Housing assistance amount dollars. amount_other_needs_assistance needs assistance amount dollars. amount_rental_assistance Rental assistance amount dollars. amount_repairs Repair assistance amount dollars. amount_replacement Replacement assistance amount dollars. amount_personal_property Personal property assistance amount dollars. amount_flood_insurance_premium_paid_by_fema FEMA-paid flood insurance premium. state_name Full state name. state_abbreviation Two-letter state abbreviation. state_code Two-digit state FIPS code.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_ihp_registrations.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Individuals and Households Program (IHP) registrations — get_ihp_registrations","text":"Data FEMA's OpenFEMA API. See https://www.fema.gov/openfema-data-page/individuals--households-program-valid-registrations-v2.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_ihp_registrations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Individuals and Households Program (IHP) registrations — get_ihp_registrations","text":"","code":"if (FALSE) { # \\dontrun{ get_ihp_registrations(    state_fips = \"NJ\",    api = TRUE) } # }"},{"path":"https://ui-research.github.io/climateapi/reference/get_lodes.html","id":null,"dir":"Reference","previous_headings":"","what":"Get LEHD Origin-Destination Employment Statistics (LODES) data — get_lodes","title":"Get LEHD Origin-Destination Employment Statistics (LODES) data — get_lodes","text":"Get LEHD Origin-Destination Employment Statistics (LODES) data","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_lodes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get LEHD Origin-Destination Employment Statistics (LODES) data — get_lodes","text":"","code":"get_lodes(   lodes_type,   jobs_type = \"all\",   states,   years,   geography = \"tract\",   state_part = \"main\" )"},{"path":"https://ui-research.github.io/climateapi/reference/get_lodes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get LEHD Origin-Destination Employment Statistics (LODES) data — get_lodes","text":"lodes_type One c(\"rac\", \"wac\", \"od\"). \"rac\" = Residence Area Characteristics, jobs associated employees' residences. \"wac\" = Workplace Area Characteristics, jobs associated employees' workplaces. \"od\" = Origin-Destination data, jobs associated workers' residences workplaces. jobs_type One c(\"\", \"primary\"). Default \"\", includes multiple jobs workers multiple jobs. \"primary\" includes highest-paying job per worker. states vector state abbreviations. years vector years. geography One c(\"block\", \"block group\", \"tract\", \"county\", \"state\"). Default \"tract\". state_part One c(\"main\", \"aux\"). Default \"main\", includes workers reside inside state work. \"aux\" returns workers work specified state live outside state.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_lodes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get LEHD Origin-Destination Employment Statistics (LODES) data — get_lodes","text":"tibble one record per geography per year per job type. Attributes include total jobs jobs worker earnings, industry, demographics; origin-destination results limited demographics compared \"wac\" \"rac\" results. year year LODES data pulled state two-digit state identifier. GEOID 11 digit identifier denoted either h_GEOID representing employees' residence census block code w_GEOID representing employees' workplace census block code job_type one either '' jobs 'federal' jobs total_jobs total number jobs given tract jobs_workers_age number employees given age range jobs_earnings number employees given monthly earnings range jobs_industry number employees given industry jobs_workers_race number employees given race, inclusive hispanic latino; available 'wac' 'rac' datasets jobs_workers_ethnicity number employess hispanic latino status, regardless race; available 'wac' 'rac' datasets jobs_workers_educational_attainment number employees highest level education attained; available 'wac' 'rac' datasets jobs_workers_sex number employees sex; available 'wac' 'rac' datasets jobs_firm_age number employees age employing firm; available 'wac' datasets jobs_firm_size number employees given range employer size; available 'wac' datasets","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_lodes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get LEHD Origin-Destination Employment Statistics (LODES) data — get_lodes","text":"Longitudinal Employer-Household Dynamics (LEHD) data U.S. Census Bureau quarterly database linked employer-employee data covering 95% employment United States. LEHD data generated merging previously collected survey administrative data jobs, businesses, workers. LEHD Origin-Destination Employment Statistics (LODES)partially synthetic dataset describes geographic patterns jobs employment locations residential locations well connections two locations. microdata link employee employer data combining administrative state unemployment insurance wage records administrative survey data. source data aggregated adjusted protect confidentiality. LODES data includes three datasets: Residence Area Characteristics (RAC): file lists total number jobs census block employee lives. Workplace Area Characteristics (WAC): file lists total number jobs census block employee works. Origin-Destination (OD): file lists job totals census block employee lives census block employee works similar County Business Patterns (CBP) data coverage employment statistics, LODES differs mainly due granular geographies (tract vs. county) focus framing statistics individual/job level found LODES data.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_naics_codes.html","id":null,"dir":"Reference","previous_headings":"","what":"Get NAICS Codes for County Business Patterns — get_naics_codes","title":"Get NAICS Codes for County Business Patterns — get_naics_codes","text":"utility function programmatically identify select NAICS codes use get_business_patterns(). wrapper around censusapi::listCensusMetadata(name = \"cbp\").","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_naics_codes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get NAICS Codes for County Business Patterns — get_naics_codes","text":"","code":"get_naics_codes(year = 2023, digits = 3)"},{"path":"https://ui-research.github.io/climateapi/reference/get_naics_codes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get NAICS Codes for County Business Patterns — get_naics_codes","text":"year vintage year NAICS codes. Data available 1986 2023. Default 2023. digits number digits desired NAICS codes. Must 2 6. Default 3. Two-digit codes represent broad industry sectors (20 codes), six-digit codes represent detailed industries.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_naics_codes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get NAICS Codes for County Business Patterns — get_naics_codes","text":"tibble following columns: naics_code NAICS code (character) naics_label descriptive label NAICS code year vintage year NAICS codes","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_naics_codes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get NAICS Codes for County Business Patterns — get_naics_codes","text":"","code":"if (FALSE) { # \\dontrun{ # Get all 2-digit NAICS codes get_naics_codes(year = 2023, digits = 2)  # Get all 3-digit NAICS codes (default) get_naics_codes(year = 2022)  # Get 4-digit NAICS codes for a specific year get_naics_codes(year = 2020, digits = 4) } # }"},{"path":"https://ui-research.github.io/climateapi/reference/get_nfip_claims.html","id":null,"dir":"Reference","previous_headings":"","what":"Access county-level data on NFIP claims — get_nfip_claims","title":"Access county-level data on NFIP claims — get_nfip_claims","text":"Retrieves National Flood Insurance Program (NFIP) claims data county level, including damage amounts, payments, building characteristics.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_nfip_claims.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Access county-level data on NFIP claims — get_nfip_claims","text":"","code":"get_nfip_claims(   county_geoids = NULL,   file_name = \"fima_nfip_claims_2025_09_09.parquet\",   api = FALSE )"},{"path":"https://ui-research.github.io/climateapi/reference/get_nfip_claims.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access county-level data on NFIP claims — get_nfip_claims","text":"county_geoids character vector five-digit county codes. NULL default; must non-NULL api = TRUE. file_name name (full path) Box file containing raw data. api TRUE, query API. FALSE default.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_nfip_claims.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Access county-level data on NFIP claims — get_nfip_claims","text":"data frame comprising county-level data current NFIP policies state_fips two-digit state identifier. state_abbreviation name state. county_geoid five-digit county identifier. county_name name county. year_construction original year construction building. year_loss year flood loss occurred. occupancy_type occupancy type primary building associated claim. count_units_insured number insured units associated claim. deductible_building total deductible buildings, main appurtenant. deductible_contents total deductible contents. value_building value main building estimated adjuster. value_contents value contents estimated adjuster. replacement_cost_building Estimated cost replace building reported insurer. replacement_cost_contents Estimated cost replace contents reported insurer. insurance_coverage_building total insurance amount building. insurance_coverage_contents total insurance amount contents. damage_building amount damage main property. damage_contents value damage contents. net_payment_building Net building payment amount. net_payment_contents Net contents payment amount. net_payment_increased_compliance Net Increased Cost Compliance (ICC) payment amount.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_nfip_claims.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Access county-level data on NFIP claims — get_nfip_claims","text":"Data FEMA's OpenFEMA API. See https://www.fema.gov/openfema-data-page/fima-nfip-redacted-claims-v2. Per FEMA: data set represents 2,000,000 NFIP claims transactions. derived NFIP system record, staged NFIP reporting platform redacted protect policy holder personally identifiable information. dataset includes 50 states + DC following territories: Puerto Rico, US Virgin Islands, Guam. order filter residential claims, filter occupancy type: \"non-residential\". claims (multi-unit buildings / condos) associated multiple insured units. calculating number units covered claim, analyst use count_units_insured column. example illustrates example data set can summarized show total number residential claims submitted two different counties, well total damages payments time period.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_nfip_claims.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Access county-level data on NFIP claims — get_nfip_claims","text":"","code":"if (FALSE) { # \\dontrun{  test <- get_nfip_claims(county_geoids = c(\"01001\", \"48201\")) |>   dplyr::filter(     year_of_loss >= 2015,  ### in the past 10 years     !occupancy_type %in% c(\"non-residential\")) |> ### only residential claims   dplyr::summarize(     .by = county_geoid,     dplyr::across(dplyr::matches(\"payment\"), sum, na.rm = TRUE),     residential_claims = dplyr::n_distinct(nfip_claim_id)) } # }"},{"path":"https://ui-research.github.io/climateapi/reference/get_nfip_policies.html","id":null,"dir":"Reference","previous_headings":"","what":"Access county-level data on NFIP policies — get_nfip_policies","title":"Access county-level data on NFIP policies — get_nfip_policies","text":"Retrieves National Flood Insurance Program (NFIP) policy data county level, including current historical policies.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_nfip_policies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Access county-level data on NFIP policies — get_nfip_policies","text":"","code":"get_nfip_policies(   state_abbreviation,   county_geoids = NULL,   file_name = \"fima_nfip_policies_2025_10_14.parquet\",   api = FALSE )"},{"path":"https://ui-research.github.io/climateapi/reference/get_nfip_policies.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access county-level data on NFIP policies — get_nfip_policies","text":"state_abbreviation 2 letter state abbreviation (e.g. TX). county_geoids character vector five-digit county codes. file_name name (full path) Box file containing raw data. api TRUE, query API. FALSE (default), read file_name.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_nfip_policies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Access county-level data on NFIP policies — get_nfip_policies","text":"dataframe project-level funding requests awards, along variables can aggregated county level. state_fips two-digit state identifier. state_abbreviation two-character abbreviation state. county_code five-digit county identifier. county_name name county. census_tract 11-digit census tract code. policy_cost cost policy summing calculated premium, reserve fund assessment, federal policy fee, HFIAA surcharge. policy_count number insured units active status associated policy. policy_rated_flood_zone NFIP flood zone. policy_premium_total_cost policy premium; negative values indicate refund. policy_date_termination date policy longer effect, either cancelled lapsed. policy_date_effective effective date flood policy. building_occupancy_type occupancy type building. building_replacement_cost insurer's estimated cost replace building.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_nfip_policies.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Access county-level data on NFIP policies — get_nfip_policies","text":"Data FEMA's OpenFEMA API. See https://www.fema.gov/openfema-data-page/fima-nfip-redacted-policies-v2. following dataset houses information NFIP policies (historic current). order filter current policies, analyst need filter policy_date_termination policy_date_effective columns. dataset also contains residential commercial policies. order filter residential policies, analyst can filter \"non-residential\" occupancy type.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_nfip_policies.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Access county-level data on NFIP policies — get_nfip_policies","text":"","code":"if (FALSE) { # \\dontrun{  test <- get_nfip_policies(       state_abbreviation = \"TX\",       county_geoids = c(\"48201\"),       file_name = \"fima_nfip_policies_2025_10_14.parquet\",       api = FALSE) |>     dplyr::filter(       !occupancy_type %in% c(\"non-residential\"), ### only residential claims,       policy_date_termination >= as.Date(\"2025-10-15\"),       policy_date_effective <= as.Date(\"2025-10-15\")) |>     dplyr::group_by(county_geoid)|>     dplyr::summarise(avg_policy_cost = mean(policy_cost)) } # }"},{"path":"https://ui-research.github.io/climateapi/reference/get_nfip_residential_penetration.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the share of residential structures covered by NFIP — get_nfip_residential_penetration","title":"Get the share of residential structures covered by NFIP — get_nfip_residential_penetration","text":"Get share residential structures covered NFIP","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_nfip_residential_penetration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the share of residential structures covered by NFIP — get_nfip_residential_penetration","text":"","code":"get_nfip_residential_penetration(   states = NULL,   file_name = \"nfip_residential_penetration_rates_12_12_2025.csv\" )"},{"path":"https://ui-research.github.io/climateapi/reference/get_nfip_residential_penetration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the share of residential structures covered by NFIP — get_nfip_residential_penetration","text":"states NULL default. file_name name (full path) raw dataset.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_nfip_residential_penetration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the share of residential structures covered by NFIP — get_nfip_residential_penetration","text":"tibble following columns: state_name State name couty_name County name GEOID Five digits county FIPS code year_data year data penetration_rate Share residential structures insured NFIP penetration_rate_sfha Share residential structures Special Flood Hazard Area insured NFIP contracts_in_force Residential NFIP contracts currently effect (\"force\") contracts_in_force_sfha Residential NFIP contracts Special Flood Hazard Area currently effect (\"force\") residential_structures number residential structures, derived 2022 National Structure Inventory residential_structures_sfha number residential structures Special Flood Hazard Area, derived 2022 National Structure Inventory","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_nfip_residential_penetration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the share of residential structures covered by NFIP — get_nfip_residential_penetration","text":"","code":"if (FALSE) { # \\dontrun{ get_nfip_residential_penetration() } # }"},{"path":"https://ui-research.github.io/climateapi/reference/get_preliminary_damage_assessments.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Data from Preliminary Damage Assessments Submitted to FEMA for Disaster Declarations — get_preliminary_damage_assessments","title":"Get Data from Preliminary Damage Assessments Submitted to FEMA for Disaster Declarations — get_preliminary_damage_assessments","text":"Retrieves data extracted PDF preliminary damage assessment (PDA) reports submitted FEMA disaster declarations.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_preliminary_damage_assessments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Data from Preliminary Damage Assessments Submitted to FEMA for Disaster Declarations — get_preliminary_damage_assessments","text":"","code":"get_preliminary_damage_assessments(   file_path = file.path(get_box_path(), \"hazards\", \"urban\",     \"preliminary-damage-assessments\", \"pda_data.csv\"),   directory_path = file.path(get_box_path(), \"hazards\", \"urban\",     \"preliminary-damage-assessments\"),   use_cache = TRUE )"},{"path":"https://ui-research.github.io/climateapi/reference/get_preliminary_damage_assessments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Data from Preliminary Damage Assessments Submitted to FEMA for Disaster Declarations — get_preliminary_damage_assessments","text":"file_path file path cached dataset, cache, path cache resulting data. directory_path path directory PDA PDFs stored. Use scrape_pda_pdfs generate files. use_cache Boolean. Read existing dataset stored file_path? FALSE, data generated anew. Else, file exists file_path, file returned.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_preliminary_damage_assessments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Data from Preliminary Damage Assessments Submitted to FEMA for Disaster Declarations — get_preliminary_damage_assessments","text":"dataframe preliminary damage assessment reports. Key columns include: disaster_number FEMA disaster number. event_type Type decision: \"approved\", \"denial\", \"appeal_approved\", \"appeal_denial\". event_title Title/description disaster event. event_date_determined Date PDA determination made. event_native_flag 1 tribal request, 0 otherwise. ia_requested 1 Individual Assistance requested, 0 otherwise. ia_residences_impacted Total residences impacted. ia_residences_destroyed Number residences destroyed. ia_residences_major_damage Number residences major damage. ia_residences_minor_damage Number residences minor damage. ia_cost_estimate_total Estimated total Individual Assistance cost. pa_requested 1 Public Assistance requested, 0 otherwise. pa_cost_estimate_total Estimated total Public Assistance cost. pa_per_capita_impact_statewide Statewide per capita impact amount. pa_per_capita_impact_indicator_statewide Met/Met indicator statewide threshold.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_preliminary_damage_assessments.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Data from Preliminary Damage Assessments Submitted to FEMA for Disaster Declarations — get_preliminary_damage_assessments","text":"Data extracted PDF reports hosted https://www.fema.gov/disaster/-declared/preliminary-damage-assessments/reports. Owing unstructured nature source documents, fields may incorrect data returned function, though significant quality checks implemented effort produce high-quality dataset.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_preliminary_damage_assessments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Data from Preliminary Damage Assessments Submitted to FEMA for Disaster Declarations — get_preliminary_damage_assessments","text":"","code":"if (FALSE) { # \\dontrun{ get_preliminary_damage_assessments() } # }"},{"path":"https://ui-research.github.io/climateapi/reference/get_public_assistance.html","id":null,"dir":"Reference","previous_headings":"","what":"Get FEMA Public Assistance (PA) funding — get_public_assistance","title":"Get FEMA Public Assistance (PA) funding — get_public_assistance","text":"Retrieves FEMA Public Assistance (PA) project funding data, crosswalked county level geographic analysis.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_public_assistance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get FEMA Public Assistance (PA) funding — get_public_assistance","text":"","code":"get_public_assistance(   file_path = file.path(get_box_path(), \"hazards\", \"fema\", \"public-assistance\", \"raw\",     \"PublicAssistanceFundedProjectsDetailsV2_2025_09_26.parquet\"),   state_abbreviations = NULL )"},{"path":"https://ui-research.github.io/climateapi/reference/get_public_assistance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get FEMA Public Assistance (PA) funding — get_public_assistance","text":"file_path file path raw data contained .parquet file. state_abbreviations character vector state abbreviations. NULL default, returns records 51 states. 51 states supported time.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_public_assistance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get FEMA Public Assistance (PA) funding — get_public_assistance","text":"dataframe project-level funding requests awards, along variables can aggregated county level. id unique identifier project raw data. field unique returned data due crosswalking statewide projects county level. Refer details additional information state_fips two-digit state identifier. state_name name state. state_abbreviation two-character USPS abbreviation state. county_fips five-digit county identifier. county_name name county. declaration_year year authorizing disaster declaration made. disaster_number FEMA-created disaster number. unique disaster-state level; example, Hurricane Helene multiple disaster numbers associated , one per state received associated disaster declaration. incident_type type disaster, e.g., \"Hurricane\". project_status current status funded PA project, e.g., \"Active\". damage_category_code letter code identifying category damages/funds may used . damage_category_description descriptive characteristization damage category. pa_federal_funding_obligated Obligated federal funding project id level. pa_federal_funding_obligated_split Obligated federal attributed id--county level. Refer details additional information.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_public_assistance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get FEMA Public Assistance (PA) funding — get_public_assistance","text":"Data FEMA's OpenFEMA API. See https://www.fema.gov/openfema-data-page/public-assistance-funded-projects-details-v2. data crosswalked estimates can  aggregated county level. necessary (county-level estimates) many projects statewide projects county-level observations data. Analysts thus two options working data: (1) De-select variables suffixed _split run distinct(df). provide unique observations projects; projects can either county-level statewide. data can aggregated state level comprehensively aggregated county level. (2) Group data county level summarize produce county-level characterizations PA projects funding, using _split-suffixed variables calculate funding totals. attribution statewide projects county level occurs proportionally attributing project costs based county-level populations. example, fictional state two counties, one population 10 one population 90, 10% statewide project's funding attributed first county 90% project's funding second county. Roughly 62 percent total PA funding returned function county-specific projects, remaining 38 percent statewide projects (2025).","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_public_assistance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get FEMA Public Assistance (PA) funding — get_public_assistance","text":"","code":"if (FALSE) { # \\dontrun{   get_public_assistance(state_abbreviations = \"NJ\") } # }"},{"path":"https://ui-research.github.io/climateapi/reference/get_sba_loans.html","id":null,"dir":"Reference","previous_headings":"","what":"Access SBA data on disaster loans — get_sba_loans","title":"Access SBA data on disaster loans — get_sba_loans","text":"Retrieves Small Business Administration (SBA) disaster loan data home business loans city zip code level.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_sba_loans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Access SBA data on disaster loans — get_sba_loans","text":"","code":"get_sba_loans()"},{"path":"https://ui-research.github.io/climateapi/reference/get_sba_loans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Access SBA data on disaster loans — get_sba_loans","text":"dataframe comprising city- zip-level data SBA loanmaking. Columns include: fiscal_year federal fiscal year loan. disaster_number_fema FEMA disaster number associated loan. disaster_number_sba_physical SBA physical disaster declaration number. disaster_number_sba_eidl SBA Economic Injury Disaster Loan (EIDL) declaration number. damaged_property_zip_code ZIP code damaged property. damaged_property_city_name City name damaged property. damaged_property_state_code Two-letter state abbreviation. verified_loss_total Total verified loss amount dollars. approved_amount_total Total approved loan amount dollars. approved_amount_real_estate Approved loan amount real estate dollars. loan_type Type loan: \"residential\" \"business\".","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_sba_loans.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Access SBA data on disaster loans — get_sba_loans","text":"Data sourced SBA's disaster loan reports. See https://www.sba.gov/funding-programs/disaster-assistance.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_sba_loans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Access SBA data on disaster loans — get_sba_loans","text":"","code":"if (FALSE) { # \\dontrun{ get_sba_loans() } # }"},{"path":"https://ui-research.github.io/climateapi/reference/get_sheldus.html","id":null,"dir":"Reference","previous_headings":"","what":"Access temporal county-level SHELDUS hazard damage data — get_sheldus","title":"Access temporal county-level SHELDUS hazard damage data — get_sheldus","text":"Retrieves county-level hazard event data Spatial Hazard Events Losses Database United States (SHELDUS), including property damage, crop damage, fatalities, injuries.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_sheldus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Access temporal county-level SHELDUS hazard damage data — get_sheldus","text":"","code":"get_sheldus(   file_path = file.path(get_box_path(), \"hazards\", \"sheldus\",     \"SHELDUS_23.0_12312023_AllCounties_CountyAggregate_YearMonthHazard_2023USD\",     \"direct_loss_aggregated_output_24075.csv\") )"},{"path":"https://ui-research.github.io/climateapi/reference/get_sheldus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access temporal county-level SHELDUS hazard damage data — get_sheldus","text":"file_path path raw SHELDUS data.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_sheldus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Access temporal county-level SHELDUS hazard damage data — get_sheldus","text":"dataframe comprising hazard x month x year x county observations hazard events. Columns include: unique_id Unique identifier observation. GEOID Five-digit county FIPS code. state_name Full state name (sentence case). county_name County name. year Year hazard event(s). month Month hazard event(s). hazard Type hazard (e.g., \"Flooding\", \"Hurricane/Tropical Storm\"). damage_property Property damage 2023 inflation-adjusted dollars. damage_crop Crop damage 2023 inflation-adjusted dollars. fatalities Number fatalities. injuries Number injuries. records Number individual events aggregated observation.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_sheldus.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Access temporal county-level SHELDUS hazard damage data — get_sheldus","text":"Data Arizona State University's SHELDUS database. Access requires subscription. See https://cemhs.asu.edu/sheldus.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_sheldus.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Access temporal county-level SHELDUS hazard damage data — get_sheldus","text":"","code":"if (FALSE) { # \\dontrun{ get_sheldus() } # }"},{"path":"https://ui-research.github.io/climateapi/reference/get_spatial_extent_census.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the Census geographies that overlap with the input spatial dataset — get_spatial_extent_census","title":"Get the Census geographies that overlap with the input spatial dataset — get_spatial_extent_census","text":"Get Census geographies overlap input spatial dataset","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_spatial_extent_census.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the Census geographies that overlap with the input spatial dataset — get_spatial_extent_census","text":"","code":"get_spatial_extent_census(data, return_geometry = FALSE, projection = 5070)"},{"path":"https://ui-research.github.io/climateapi/reference/get_spatial_extent_census.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the Census geographies that overlap with the input spatial dataset — get_spatial_extent_census","text":"data sf-formatted dataframe return_geometry Logical. Include geometries returned geographies? projection EPSG code desired projection. Default 5070 (Albers Equal Area).","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_spatial_extent_census.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the Census geographies that overlap with the input spatial dataset — get_spatial_extent_census","text":"tibble (sf object return_geometry = TRUE) containing Census geographies overlap input spatial data. structure depends geographic extent: multiple states overlap Returns state-level data columns: state_geoid (2-digit FIPS), geography (\"state\"). single state overlaps Returns tract-level data columns: state_geoid (2-digit FIPS), county_geoid (5-digit FIPS), geography (\"tract\"). return_geometry = TRUE, geometry column retained; otherwise dropped.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_structures.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate counts of hazard-impacted structures by structure type — get_structures","title":"Estimate counts of hazard-impacted structures by structure type — get_structures","text":"Retrieves building footprint data USA Structures dataset summarizes structure counts type tract county level.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_structures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate counts of hazard-impacted structures by structure type — get_structures","text":"","code":"get_structures(boundaries, geography = \"county\", keep_structures = FALSE)"},{"path":"https://ui-research.github.io/climateapi/reference/get_structures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate counts of hazard-impacted structures by structure type — get_structures","text":"boundaries POLYGON MULTIPOLYGON object, sf::st_bbox()-style bbox. geography desired geography results. One \"tract\" \"county\". keep_structures Logical. TRUE, raw structure data returned alongside summarized data.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_structures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate counts of hazard-impacted structures by structure type — get_structures","text":"Depends keep_structures parameter: keep_structures = FALSE (default): tibble containing structure counts aggregated geography occupancy type, columns: GEOID Character. Census geography identifier (county FIPS tract GEOID depending geography parameter). primary_occupancy Character. primary occupancy classification structures (e.g., \"Single Family Dwelling\", \"Multi - Family Dwelling\"). occupancy_class Character. Broad occupancy classification (e.g., \"Residential\", \"Commercial\"). count Integer. Number structures occupancy type geography. keep_structures = TRUE: named list two elements: structures_summarized aggregated tibble described . structures_raw sf object (POINT geometry) containing individual structure records columns: unique_id (building ID), occupancy_class, primary_occupancy, county_fips, geometry.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_structures.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate counts of hazard-impacted structures by structure type — get_structures","text":"","code":"if (FALSE) { # \\dontrun{ get_structures(   geography = \"tract\",   boundaries = tigris::states(cb = TRUE) %>% dplyr::filter(stringr::str_detect(NAME, \"District\"))) } # }"},{"path":"https://ui-research.github.io/climateapi/reference/get_system_username.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the user's username — get_system_username","title":"Get the user's username — get_system_username","text":"Get user's username","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_system_username.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the user's username — get_system_username","text":"","code":"get_system_username()"},{"path":"https://ui-research.github.io/climateapi/reference/get_system_username.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the user's username — get_system_username","text":"character string containing system username. Uses Sys.info()[\"user\"] works reliably across Windows, Mac, Linux.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_system_username.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the user's username — get_system_username","text":"","code":"if (FALSE) { # \\dontrun{ get_system_username() } # }"},{"path":"https://ui-research.github.io/climateapi/reference/get_wildfire_burn_zones.html","id":null,"dir":"Reference","previous_headings":"","what":"Get wildfire burn zones — get_wildfire_burn_zones","title":"Get wildfire burn zones — get_wildfire_burn_zones","text":"Returns spatial data wildfire burn zones US 2000-2025. dataset harmonizes six wildfire datasets (FIRED, MTBS, NIFC, ICS-209, RedBook, FEMA) identify wildfires burned near communities resulted civilian fatalities, destroyed structures, received federal disaster relief.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_wildfire_burn_zones.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get wildfire burn zones — get_wildfire_burn_zones","text":"","code":"get_wildfire_burn_zones(   file_path = file.path(get_box_path(), \"hazards\", \"other-sources\",     \"wildfire-burn-zones\", \"wfbz_disasters_2000-2025.geojson\") )"},{"path":"https://ui-research.github.io/climateapi/reference/get_wildfire_burn_zones.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get wildfire burn zones — get_wildfire_burn_zones","text":"file_path path geojson file containing raw data. Defaults path within Box.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_wildfire_burn_zones.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get wildfire burn zones — get_wildfire_burn_zones","text":"sf dataframe comprising wildfire burn zone disasters. row represents single wildfire event, polygon geometries representing burn zones. Columns include: wildfire_id Unique identifier wildfire event. id_fema FEMA disaster identifier (applicable). year Year wildfire. wildfire_name Name wildfire fire complex. county_fips Pipe-delimited string five-digit county FIPS codes counties affected wildfire. county_name Pipe-delimited string county names counties affected wildfire. area_sq_km Burned area square kilometers. wildfire_complex_binary Whether fire complex (multiple fires). date_start Ignition date. date_containment Containment date. fatalities_total Total fatalities. injuries_total Total injuries. structures_destroyed Number structures destroyed. structures_threatened Number structures threatened. evacuation_total Total evacuations. wui_type Wildland-urban interface type. density_people_sq_km_wildfire_buffer Population density wildfire buffer area. geometry Burn zone polygon geometry.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_wildfire_burn_zones.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get wildfire burn zones — get_wildfire_burn_zones","text":"Data harmonized wildfire burn zone disaster dataset combining FIRED, MTBS, NIFC, ICS-209, RedBook, FEMA data sources. Geometries NAD83 / Conus Albers (EPSG:5070).","code":""},{"path":"https://ui-research.github.io/climateapi/reference/get_wildfire_burn_zones.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get wildfire burn zones — get_wildfire_burn_zones","text":"","code":"if (FALSE) { # \\dontrun{ burn_zones <- get_wildfire_burn_zones() } # }"},{"path":"https://ui-research.github.io/climateapi/reference/inflation_adjust.html","id":null,"dir":"Reference","previous_headings":"","what":"Inflation adjust dollar values using annual PCE Index — inflation_adjust","title":"Inflation adjust dollar values using annual PCE Index — inflation_adjust","text":"Personal Consumption Expenditures Price Index (PCE Index) Federal Reserve Bank St. Louis's FRED tool.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/inflation_adjust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inflation adjust dollar values using annual PCE Index — inflation_adjust","text":"","code":"inflation_adjust(   df,   year_variable,   dollar_variables,   names_suffix = NULL,   base_year = 2024 )"},{"path":"https://ui-research.github.io/climateapi/reference/inflation_adjust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inflation adjust dollar values using annual PCE Index — inflation_adjust","text":"df dataframe values inflation-adjust year_variable name column denoting year existing dollar-denominated figures based . dollar_variables variables inflation-adjust. names_suffix suffix add names inflation-adjusted variables. NULL, defaults \"_<base_year>\". \"\", columns renamed place. base_year year use base inflation adjustment. NULL, defaults recent year PCE index data.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/inflation_adjust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inflation adjust dollar values using annual PCE Index — inflation_adjust","text":"tibble identical input df additional inflation-adjusted columns. column specified dollar_variables, new column created name plus names_suffix (default: \"_base_year\"). adjusted values calculated multiplying original values inflation factor derived PCE Price Index ratio base year observation's year. Original columns preserved unchanged.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/inflation_adjust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inflation adjust dollar values using annual PCE Index — inflation_adjust","text":"","code":"if (FALSE) { # \\dontrun{ df = tibble::tribble(   ~ year, ~ amount,   1990, 1,   1991, 1,   1992, 1)  df |>   inflation_adjust(     year_variable = year,     dollar_variables = amount,     names_suffix = \"inflation_adjusted\") } # }"},{"path":"https://ui-research.github.io/climateapi/reference/interpolate_demographics.html","id":null,"dir":"Reference","previous_headings":"","what":"Interpolate tract-level sociodemographic data to zoning polygons — interpolate_demographics","title":"Interpolate tract-level sociodemographic data to zoning polygons — interpolate_demographics","text":"Interpolate tract-level sociodemographic data zoning polygons","code":""},{"path":"https://ui-research.github.io/climateapi/reference/interpolate_demographics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interpolate tract-level sociodemographic data to zoning polygons — interpolate_demographics","text":"","code":"interpolate_demographics(   zones_sf,   sociodemographic_tracts_sf = NULL,   id_column,   weights = \"population\" )"},{"path":"https://ui-research.github.io/climateapi/reference/interpolate_demographics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interpolate tract-level sociodemographic data to zoning polygons — interpolate_demographics","text":"zones_sf spatial (sf) dataset defining zoning districts. sociodemographic_tracts_sf (optional) tract level spatial (sf) dataset resulting urbnindicators. NULL, function run behind scenes appropriate tracts. id_column name column zones_sf identifies unique combination zoning regulations. weights One c(\"population\", \"housing\"). variable used weight interpolation.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/interpolate_demographics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interpolate tract-level sociodemographic data to zoning polygons — interpolate_demographics","text":"spatial (sf) dataset comprising one observation level id_column interpolated values taken sociodemographic_tracts_sf.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/polygons_to_linestring.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert polygons into their component linestrings — polygons_to_linestring","title":"Convert polygons into their component linestrings — polygons_to_linestring","text":"Convert polygons component linestrings","code":""},{"path":"https://ui-research.github.io/climateapi/reference/polygons_to_linestring.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert polygons into their component linestrings — polygons_to_linestring","text":"","code":"polygons_to_linestring(.sf)"},{"path":"https://ui-research.github.io/climateapi/reference/polygons_to_linestring.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert polygons into their component linestrings — polygons_to_linestring","text":".sf spatial dataframe containing one polygons","code":""},{"path":"https://ui-research.github.io/climateapi/reference/polygons_to_linestring.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert polygons into their component linestrings — polygons_to_linestring","text":"sf object (simple feature collection) geometry type LINESTRING. returned object contains: polygon_id Integer. row index originating polygon input .sf object, enabling linkage back source polygon. line_id Integer. sequential identifier line segment within originating polygon. Line segments ordered according vertex sequence polygon boundary. ... original attributes input .sf object preserved joined back via polygon_id. geometry LINESTRING geometry. line segment represents one edge original polygon boundary. CRS output matches input .sf object (transformed EPSG:5070 processing).","code":""},{"path":"https://ui-research.github.io/climateapi/reference/qualtrics_define_missing.html","id":null,"dir":"Reference","previous_headings":"","what":"Fill in missing and non-missing values across interrelated survey questions — qualtrics_define_missing","title":"Fill in missing and non-missing values across interrelated survey questions — qualtrics_define_missing","text":"Fill missing non-missing values across interrelated survey questions","code":""},{"path":"https://ui-research.github.io/climateapi/reference/qualtrics_define_missing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fill in missing and non-missing values across interrelated survey questions — qualtrics_define_missing","text":"","code":"qualtrics_define_missing(   df,   question_code_include,   question_code_omit = NULL,   default_values = list(\"No\", 0, as.Date(0)),   predicate_question = NULL,   predicate_question_negative_value = NULL )"},{"path":"https://ui-research.github.io/climateapi/reference/qualtrics_define_missing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fill in missing and non-missing values across interrelated survey questions — qualtrics_define_missing","text":"df dataframe survey responses question_code_include regex matches columns include missing non-missing value imputation question_code_omit regex matches columns omit missing non-missing value imputation default_values list length three, specifying default, non-missing values used character, numeric, Date columns, respectively predicate_question Optional. name single column controls whether columns selected question_code_include predicate_question_negative_value predicate_question specified, provide value indicates negative response predicate question. responses predicate question value, value imputed specified columns","code":""},{"path":"https://ui-research.github.io/climateapi/reference/qualtrics_define_missing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fill in missing and non-missing values across interrelated survey questions — qualtrics_define_missing","text":"tibble containing columns selected question_code_include (excluding matching question_code_omit), missing values handled according following logic: Without predicate_question selected columns NA row, values remain NA. selected column non-NA value, NA values selected columns replaced appropriate default value default_values based column type. predicate_question predicate question NA, selected columns set NA. predicate question equals predicate_question_negative_value , selected columns set appropriate default value. Otherwise, original values preserved. Column types default value mappings: character uses default_values[[1]], numeric uses default_values[[2]], Date/POSIXct uses default_values[[3]].","code":""},{"path":"https://ui-research.github.io/climateapi/reference/qualtrics_format_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Prep Qualtrics metadata — qualtrics_format_metadata","title":"Prep Qualtrics metadata — qualtrics_format_metadata","text":"Prep Qualtrics metadata","code":""},{"path":"https://ui-research.github.io/climateapi/reference/qualtrics_format_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prep Qualtrics metadata — qualtrics_format_metadata","text":"","code":"qualtrics_format_metadata(metadata, sections = c(), text_replace = \"zzzzz\")"},{"path":"https://ui-research.github.io/climateapi/reference/qualtrics_format_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prep Qualtrics metadata — qualtrics_format_metadata","text":"metadata dataframe containing unprocessed metadata Qualtrics API sections named vector specifying last question number survey section text_replace named character vector regex patterns replace metadata","code":""},{"path":"https://ui-research.github.io/climateapi/reference/qualtrics_format_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prep Qualtrics metadata — qualtrics_format_metadata","text":"tibble containing formatted Qualtrics survey metadata following columns: question_number Integer. sequential position question survey (1-indexed). question_name Character. internal Qualtrics question identifier (e.g., \"Q1\", \"Q2_1\"). text_main Character. primary question text, patterns specified text_replace substituted. text_sub Character. sub-question response option text, patterns specified text_replace substituted. survey_section Character. name survey section question belongs, defined sections parameter. Filled upward section boundaries.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/qualtrics_get_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Access Qualtrics metadata — qualtrics_get_metadata","title":"Access Qualtrics metadata — qualtrics_get_metadata","text":"Access Qualtrics metadata","code":""},{"path":"https://ui-research.github.io/climateapi/reference/qualtrics_get_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Access Qualtrics metadata — qualtrics_get_metadata","text":"","code":"qualtrics_get_metadata(   metadata,   question_name = NULL,   survey_section = NULL,   return_values = \"text_sub\" )"},{"path":"https://ui-research.github.io/climateapi/reference/qualtrics_get_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access Qualtrics metadata — qualtrics_get_metadata","text":"metadata dataframe containing Qualtrics metadata question_name regex pattern match question name(s) survey_section regex pattern match survey section(s) return_values name column (character) returned","code":""},{"path":"https://ui-research.github.io/climateapi/reference/qualtrics_get_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Access Qualtrics metadata — qualtrics_get_metadata","text":"character vector containing values column specified return_values (default: \"text_sub\"), filtered rows matching either question_name survey_section pattern. length vector corresponds number matching rows metadata. Returns empty character vector matches found.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/qualtrics_plot_question.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot responses to Qualtrics survey questions — qualtrics_plot_question","title":"Plot responses to Qualtrics survey questions — qualtrics_plot_question","text":"Plot responses Qualtrics survey questions","code":""},{"path":"https://ui-research.github.io/climateapi/reference/qualtrics_plot_question.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot responses to Qualtrics survey questions — qualtrics_plot_question","text":"","code":"qualtrics_plot_question(   df,   metadata,   question_code_include,   question_code_omit = \"zzzzz\",   question_type,   title = \"\",   subtitle = NULL,   subtitle_replace = c(`\\\\[Field.*\\\\]` = \"your community\",     `Your best estimate is fine\\\\.` = \"\"),   text_remove = \"please describe|please specify\",   text_replace = c(a = \"a\"),   omit_other = TRUE )"},{"path":"https://ui-research.github.io/climateapi/reference/qualtrics_plot_question.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot responses to Qualtrics survey questions — qualtrics_plot_question","text":"df dataframe survey responses metadata dataframe Qualtrics metadata question_code_include regex matches question codes include plot question_code_omit regex matches question codes omit plot question_type one c(\"continuous\", \"checkbox_single\", \"checkbox_multi\", \"checkbox_factor\") title Plot title subtitle Plot subtitle subtitle_replace named character vector regex patterns replace subtitle text_remove regex pattern select response options exclude plot text_replace named character vector regex patterns replace response text omit_other Logical; whether omit \"\" response option. Default TRUE.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/qualtrics_plot_question.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot responses to Qualtrics survey questions — qualtrics_plot_question","text":"ggplot2 object representing visualization survey responses. plot type varies based question_type: \"continuous\" boxplot showing distribution numeric responses, question sub-text y-axis values x-axis. Multiple sub-questions displayed separate boxplots. \"checkbox_single\" \"checkbox_multi\" horizontal bar chart showing response counts. Response options ordered total count (descending). \"checkbox_multi\", bars stacked response type. \"checkbox_factor\" stacked horizontal bar chart showing response counts factor level, response options ordered total count. plot uses Urban Institute theming via urbnthemes::theme_urbn_print() includes specified title auto-generated custom subtitle.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/read_ipums_cached.html","id":null,"dir":"Reference","previous_headings":"","what":"Read IPUMS data leveraging a local cache — read_ipums_cached","title":"Read IPUMS data leveraging a local cache — read_ipums_cached","text":"script wraps standard ipumsr::read_ipums*() query workflow, addressing two common challenges: (1) default workflow downloads arbitrarily named raw data files sequentially numbered dependent total number extracts submitted given user; (2) default workflow provide inbuilt capacity check local version query re-submitting API. script addresses challenges taking user-supplied filename file directory, checking existing file path, otherwise downloading extract (user-specified) given filepath.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/read_ipums_cached.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read IPUMS data leveraging a local cache — read_ipums_cached","text":"","code":"read_ipums_cached(   filename,   download_directory,   extract_definition,   refresh = FALSE )"},{"path":"https://ui-research.github.io/climateapi/reference/read_ipums_cached.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read IPUMS data leveraging a local cache — read_ipums_cached","text":"filename name file (full file path). download_directory path specifying download data. extract_definition define_extract_micro() define_extract_agg() object. refresh true, execute API query, even data already stored locally. Defaults FALSE.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/read_ipums_cached.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read IPUMS data leveraging a local cache — read_ipums_cached","text":"tibble containing IPUMS data corresponding supplied extract_definition. structure varies collection type: microdata collections (e.g., \"usa\", \"cps\") Returns individual-level records columns corresponding variables specified extract definition. Column names types determined IPUMS variable specifications. data read via ipumsr::read_ipums_micro(). aggregate collections (\"nhgis\", \"ihgis\") Returns aggregate data (typically geographic summary levels) columns corresponding requested tables/variables. IPUMS variable attributes applied via collection's codebook. data read via ipumsr::read_ipums_agg(). cached file exists specified path refresh = FALSE, cached data returned warning. Otherwise, extract submitted IPUMS, downloaded, cached future use.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/read_ipums_cached.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read IPUMS data leveraging a local cache — read_ipums_cached","text":"","code":"if (FALSE) { # \\dontrun{ read_ipums_cached(   filename = \"acs_insurance_race_2022_1yr_repweights\",   download_directory = file.path(\"data\"),   extract_definition = ipumsr::define_extract_micro(     collection = \"usa\",     description = \"2022 ACS 1-year sample with replicate weights - insurance and race\",     samples = c(\"us2022a\"),     variables = list(       \"HCOVANY\",       ipumsr::var_spec(\"RACE\", case_selections = c(\"1\", \"2\")))),   refresh = FALSE) } # }"},{"path":"https://ui-research.github.io/climateapi/reference/read_xlsx_from_url.html","id":null,"dir":"Reference","previous_headings":"","what":"Download a .xlsx file(s) from a URL(s) — read_xlsx_from_url","title":"Download a .xlsx file(s) from a URL(s) — read_xlsx_from_url","text":"Download .xlsx file(s) URL(s)","code":""},{"path":"https://ui-research.github.io/climateapi/reference/read_xlsx_from_url.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download a .xlsx file(s) from a URL(s) — read_xlsx_from_url","text":"","code":"read_xlsx_from_url(urls, directory, file_names = NULL, silent = TRUE)"},{"path":"https://ui-research.github.io/climateapi/reference/read_xlsx_from_url.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download a .xlsx file(s) from a URL(s) — read_xlsx_from_url","text":"urls character vector URLs length one greater. directory path single directory–file–.xlsx file(s) saved. file_names Optionally, character vector length urls containing file names (full paths) downloaded files named. NULL (default), file names extracted urls. silent TRUE (default), files saved silently. FALSE, downloaded files read returned list.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/read_xlsx_from_url.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download a .xlsx file(s) from a URL(s) — read_xlsx_from_url","text":"silent = TRUE (default): Returns NULL invisibly. Files downloaded saved directory. silent = FALSE: Returns list data frames, one per URL, containing contents downloaded .xlsx file read openxlsx::read.xlsx(). List elements order input urls.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/subdivide_linestring.html","id":null,"dir":"Reference","previous_headings":"","what":"Subdivide a linestring into segments of a specified length — subdivide_linestring","title":"Subdivide a linestring into segments of a specified length — subdivide_linestring","text":"Subdivide linestring segments specified length","code":""},{"path":"https://ui-research.github.io/climateapi/reference/subdivide_linestring.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subdivide a linestring into segments of a specified length — subdivide_linestring","text":"","code":"subdivide_linestring(line, max_length, crs = 5070)"},{"path":"https://ui-research.github.io/climateapi/reference/subdivide_linestring.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subdivide a linestring into segments of a specified length — subdivide_linestring","text":"line linestring simple feature collection thereof max_length maximum length segment. Segments longer value subdivided; threshold returned -. crs coordinate reference system linestring transformed. Default 5070.","code":""},{"path":"https://ui-research.github.io/climateapi/reference/subdivide_linestring.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subdivide a linestring into segments of a specified length — subdivide_linestring","text":"sf object (simple feature collection) geometry type LINESTRING. returned object contains: row_id Integer. row index original input linestring, allowing linkage back input data. ... original attributes input line object preserved joined back via row_id. geometry LINESTRING geometry. segment max_length units long (CRS units). Segments shorter max_length input returned unchanged. CRS output set value specified crs parameter (default: EPSG:5070).","code":""},{"path":[]},{"path":"https://ui-research.github.io/climateapi/news/index.html","id":"v0009001-development-version","dir":"Changelog","previous_headings":"","what":"v0.0.0.9001","title":"climateapi (development version)","text":"Updating README Reorganizing References Adding business patterns data","code":""}]
